{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import train as t\n",
    "from src import helper_models as hm, helper_data as hd, helper_tts as htts\n",
    "from importlib import reload\n",
    "import keras, glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.helper_tts' from '/mnt/volume2Tb/Dropbox/PROJECTS/MACHINE-LEARNING/AQUASCOPE/plankifier/src/helper_tts.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload imports of custom modules, in case I am modifying and reloading them live\n",
    "reload(t)\n",
    "reload(hd)\n",
    "reload(hm)\n",
    "reload(htts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=t.Ctrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init parameters\n",
    "Parameters must always be updated through the `UpdateParams()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetModelParams(kind):\n",
    "    ''' \n",
    "    A quick way to set compatible user parameters of data and model kinds\n",
    "    \n",
    "    Input: kind = either 'image', 'feat' or 'mixed'\n",
    "    Output: model_image, model_feat, datakind, ttkind, aug\n",
    "    '''\n",
    "    \n",
    "    if kind == 'image':\n",
    "        return ('conv2', None, 'image', 'image', True)\n",
    "    \n",
    "    elif kind == 'feat':\n",
    "        return (None, 'mlp', 'feat', 'feat', False)\n",
    "    \n",
    "    elif kind == 'mixed':\n",
    "        return ('conv2', 'mlp', 'mixed', 'mixed', False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_image, model_feat, datakind, ttkind, aug = SetModelParams('image')\n",
    "\n",
    "sim.UpdateParams(\n",
    "    datapaths=['./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28/',\n",
    "               './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.07.06/'],\n",
    "    outpath     = 'out_example', \n",
    "    L           = 128, \n",
    "    aug         = aug, \n",
    "    model_feat  = model_feat,\n",
    "    model_image = model_image,\n",
    "    datakind    = datakind, \n",
    "    ttkind      = ttkind,\n",
    "    class_select= None #['chaoborus','bosmina','unknown_plankton'] \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output directory only after you've set the right `outpath`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.CreateOutDir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28/', './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.07.06/']\n"
     ]
    }
   ],
   "source": [
    "print(sim.params.datapaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapaths: ['./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28/', './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.07.06/']\n",
      "classes from datapaths: ['kellikottia', 'copepod_skins', 'uroglena', 'conochilus', 'bosmina', 'nauplius', 'unknown', 'diatom_chain', 'dinobryon', 'ceratium', 'daphnia', 'fragilaria', 'maybe_cyano', 'leptodora', 'daphnia_skins', 'synchaeta', 'fish', 'rotifers', 'trichocerca', 'cyclops', 'polyarthra', 'chaoborus', 'aphanizomenon', 'paradileptus', 'keratella_quadrata', 'unknown_plankton', 'filament', 'dirt', 'keratella_cochlearis', 'asplanchna', 'eudiaptomus', 'hydra', 'asterionella', 'diaphanosoma']\n",
      "class: kellikottia (519)\n",
      "class: copepod_skins (33)\n",
      "class: uroglena (953)\n",
      "class: conochilus (264)\n",
      "class: bosmina (81)\n",
      "class: nauplius (1507)\n",
      "class: unknown (245)\n",
      "class: diatom_chain (17)\n",
      "class: dinobryon (3321)\n",
      "class: ceratium (814)\n",
      "class: daphnia (721)\n",
      "class: fragilaria (306)\n",
      "class: maybe_cyano (1364)\n",
      "class: leptodora (203)\n",
      "class: daphnia_skins (46)\n",
      "class: synchaeta (142)\n",
      "class: fish (222)\n",
      "class: rotifers (744)\n",
      "class: trichocerca (255)\n",
      "class: cyclops (866)\n",
      "class: polyarthra (80)\n",
      "class: chaoborus (10)\n",
      "class: aphanizomenon (225)\n",
      "class: paradileptus (424)\n",
      "class: keratella_quadrata (420)\n",
      "class: unknown_plankton (71)\n",
      "class: filament (405)\n",
      "class: dirt (131)\n",
      "class: keratella_cochlearis (215)\n",
      "class: asplanchna (607)\n",
      "class: eudiaptomus (537)\n",
      "class: hydra (18)\n",
      "class: asterionella (1055)\n",
      "class: diaphanosoma (1089)\n"
     ]
    }
   ],
   "source": [
    "# These arguments are the defaults\n",
    "reload(hd)\n",
    "sim.LoadData(L=sim.params.L, class_select=sim.params.class_select, datakind=sim.params.datakind) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sets (test and train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.UpdateParams(testSplit=0.3)\n",
    "sim.CreateTrainTestSets(ttkind=sim.params.ttkind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Model\n",
    "Custom parameter changes are made by acting directly on the params class through the `UpdateParams()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: At the current state, we are taking the default weight initialization, whatever it is. This must change in order to have better control.\n",
      "Train on 112 samples, validate on 49 samples\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 1.5551 - accuracy: 0.0714 - val_loss: 1.4246 - val_accuracy: 0.0408\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.5214 - accuracy: 0.0714 - val_loss: 1.4213 - val_accuracy: 0.0408\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.4897 - accuracy: 0.1161 - val_loss: 1.4182 - val_accuracy: 0.0408\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.4606 - accuracy: 0.1607 - val_loss: 1.4151 - val_accuracy: 0.0408\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.4329 - accuracy: 0.2054 - val_loss: 1.4122 - val_accuracy: 0.0408\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.4077 - accuracy: 0.2768 - val_loss: 1.4093 - val_accuracy: 0.0408\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.3845 - accuracy: 0.3393 - val_loss: 1.4065 - val_accuracy: 0.0408\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.3624 - accuracy: 0.4018 - val_loss: 1.4037 - val_accuracy: 0.0408\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.3422 - accuracy: 0.4196 - val_loss: 1.4010 - val_accuracy: 0.0408\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.3237 - accuracy: 0.4554 - val_loss: 1.3983 - val_accuracy: 0.0408\n",
      "Training took 0.07678954601287842 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n"
     ]
    }
   ],
   "source": [
    "sim.UpdateParams(totEpochs=10)\n",
    "# print(sim.tt.trainXfeat.shape)\n",
    "sim.Train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         bosmina       0.00      0.00      0.00        27\n",
      "       chaoborus       0.04      1.00      0.08         2\n",
      "unknown_plankton       0.00      0.00      0.00        20\n",
      "\n",
      "        accuracy                           0.04        49\n",
      "       macro avg       0.01      0.33      0.03        49\n",
      "    weighted avg       0.00      0.04      0.00        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sim.Report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract manually the training loss corresponding to the best weights, so that we can make sure that restarting the simulation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training loss: 1.5551090240478516\n",
      "Best    training loss: 1.32373046875\n"
     ]
    }
   ],
   "source": [
    "def BestLoss(history):\n",
    "    ''' Returns the training loss of the point where the validation loss was minimal'''\n",
    "    return history['loss'][np.argmin(history['val_loss'])]\n",
    "def InitLoss(history):\n",
    "    ''' Returns the training loss of the point where the validation loss was minimal'''\n",
    "    return history['loss'][0]\n",
    "\n",
    "# initLoss = InitLoss(sim.history.history)\n",
    "# bestLoss = BestLoss(sim.history.history)\n",
    "\n",
    "print('Initial training loss:',InitLoss(sim.history.history))\n",
    "print('Best    training loss:',BestLoss(sim.history.history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start again from scratch\n",
    "If we train again, the simulation does not start again where it ended, but it starts from scratch.\n",
    "Since the default initialization is random, the initial value will be close to that of the previous run, but not the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: At the current state, we are taking the default weight initialization, whatever it is. This must change in order to have better control.\n",
      "Train on 112 samples, validate on 49 samples\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 1.0875 - accuracy: 0.4107 - val_loss: 1.1422 - val_accuracy: 0.4082\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0756 - accuracy: 0.4286 - val_loss: 1.1410 - val_accuracy: 0.4082\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0649 - accuracy: 0.4286 - val_loss: 1.1397 - val_accuracy: 0.4082\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0530 - accuracy: 0.4464 - val_loss: 1.1384 - val_accuracy: 0.4082\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0426 - accuracy: 0.4554 - val_loss: 1.1372 - val_accuracy: 0.4082\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0327 - accuracy: 0.4643 - val_loss: 1.1359 - val_accuracy: 0.4082\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0232 - accuracy: 0.4821 - val_loss: 1.1347 - val_accuracy: 0.4082\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0145 - accuracy: 0.4821 - val_loss: 1.1334 - val_accuracy: 0.4082\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0060 - accuracy: 0.4821 - val_loss: 1.1322 - val_accuracy: 0.4082\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9977 - accuracy: 0.4821 - val_loss: 1.1309 - val_accuracy: 0.4082\n",
      "Training took 0.0767725666364034 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n"
     ]
    }
   ],
   "source": [
    "sim.Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training loss: 1.087547745023455\n",
      "Best    training loss: 0.9976513385772705\n"
     ]
    }
   ],
   "source": [
    "print('Initial training loss:',InitLoss(sim.history.history))\n",
    "print('Best    training loss:',BestLoss(sim.history.history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from a previous state\n",
    "We have two ways of not starting from scratch. We can either *(a)* define the full model and load the weight configuration, or *(b)* load the full model. We could also load the full model and then load a different weight configuration *(b+a)*.\n",
    "\n",
    "I also show how to play around with some input parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Define model and load weights from disk\n",
    "We don't update the parameters, because we keep the same ones as in the previous runs, for comparison. The only thing we need to do, before calling `sim.Train()`, is to specify the file with the weight configuration through the `load_weights` parameter.\n",
    "\n",
    "We will load the weights that minimized the test loss in the previous run.\n",
    "You will see now that the initial loss is lower value than that of the two previous runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  out_example/bestweights.hdf5\n",
      "Train on 112 samples, validate on 49 samples\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 1s 4ms/step - loss: 0.9900 - accuracy: 0.5000 - val_loss: 1.1297 - val_accuracy: 0.4082\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9827 - accuracy: 0.5179 - val_loss: 1.1285 - val_accuracy: 0.4082\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9763 - accuracy: 0.5089 - val_loss: 1.1272 - val_accuracy: 0.4082\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9700 - accuracy: 0.5179 - val_loss: 1.1260 - val_accuracy: 0.4082\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9631 - accuracy: 0.5179 - val_loss: 1.1248 - val_accuracy: 0.4082\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9577 - accuracy: 0.5357 - val_loss: 1.1236 - val_accuracy: 0.4082\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9529 - accuracy: 0.5357 - val_loss: 1.1223 - val_accuracy: 0.4082\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9472 - accuracy: 0.5268 - val_loss: 1.1211 - val_accuracy: 0.4082\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.5268 - val_loss: 1.1199 - val_accuracy: 0.4082\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.9373 - accuracy: 0.5446 - val_loss: 1.1186 - val_accuracy: 0.4082\n",
      "Training took 0.08215785026550293 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n"
     ]
    }
   ],
   "source": [
    "# Load the weights\n",
    "sim.params.load_weights=sim.params.outpath+'/bestweights.hdf5'\n",
    "sim.Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training loss: 0.990047982760838\n",
      "Best    training loss: 0.9372863599232265\n"
     ]
    }
   ],
   "source": [
    "print('Initial training loss:', InitLoss(sim.history.history))\n",
    "print('Best    training loss:', BestLoss(sim.history.history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Loading full model from disk (CHECKPOINTING)\n",
    "This is essentially what we do when checkpointing. At the end of each run, the entire model is saved (the default name is `'keras_model.h5'`). If we want to restart from there, we just need to load that model.\n",
    "\n",
    "Since in this case we are checkpointing, we also show how to handle the simulation times.\n",
    "Since when checkpointing one usually is starting a simulation from scratch, we will **define a new Ctrain class that loads all the parameters**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model, classes and parameters from the end of the previous run\n",
    "model_from_previous  = sim.params.outpath+'/'+sim.params.saveModelName\n",
    "params_from_previous = np.load(sim.params.outpath+'/params.npy', allow_pickle=True).item()\n",
    "classes_from_previous = np.load(sim.params.outpath+'/classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapaths: ['./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28/', './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.07.06/']\n",
      "classes from datapaths: ['leptodora', 'aphanizomenon', 'nauplius', 'fish', 'ceratium', 'bosmina', 'keratella_quadrata', 'rotifers', 'hydra', 'polyarthra', 'daphnia_skins', 'uroglena', 'trichocerca', 'fragilaria', 'diaphanosoma', 'diatom_chain', 'daphnia', 'cyclops', 'asterionella', 'copepod_skins', 'unknown_plankton', 'dirt', 'unknown', 'filament', 'paradileptus', 'kellikottia', 'chaoborus', 'keratella_cochlearis', 'synchaeta', 'eudiaptomus', 'asplanchna', 'dinobryon', 'maybe_cyano', 'conochilus']\n",
      "class: chaoborus (10)\n",
      "class: bosmina (80)\n",
      "class: unknown_plankton (71)\n"
     ]
    }
   ],
   "source": [
    "# Create a new class, just as if we were starting a new simulation that loaded a previous checkpoint\n",
    "sim2=t.Ctrain()\n",
    "sim2.params = params_from_previous\n",
    "sim2.CreateOutDir()\n",
    "sim2.LoadData(L=sim.params.L, class_select=sim.params.class_select, datakind=sim.params.datakind) # Should make a deep copy from sim\n",
    "sim2.CreateTrainTestSets(ttkind=sim.params.ttkind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model without training it, and make a classification report**. You can see that the model is loaded correctly, since it gives better than random predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: At the current state, we are taking the default weight initialization, whatever it is. This must change in order to have better control.\n",
      "Training took 0.002076117197672526 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         bosmina       0.56      0.37      0.44        27\n",
      "       chaoborus       0.06      1.00      0.12         2\n",
      "unknown_plankton       0.00      0.00      0.00        20\n",
      "\n",
      "        accuracy                           0.24        49\n",
      "       macro avg       0.21      0.46      0.19        49\n",
      "    weighted avg       0.31      0.24      0.25        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sim2.Train(train=False) #This only loads the model\n",
    "sim2.Report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prolongate the run for some more steps.\n",
    "Since we are prolongating a run, we also want to make sure that the timesteps are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial epoch to the end of the previous run, and extend the total number of epochs (otherwise it won't run)\n",
    "n_epochs_new = 20\n",
    "\n",
    "sim2.params.initial_epoch=sim.history.epoch[-1]+1 if len(sim.history.epoch)>0 else 0\n",
    "sim2.params.totEpochs=sim2.params.initial_epoch + n_epochs_new\n",
    "\n",
    "# We do not want the Train() method to load weights from somewhere, \n",
    "# so we make sure that load_weights is set to None\n",
    "# If we wanted to load the weights from somewhere, \n",
    "# it would be enough to give it the right file name (usually, 'bestweights.hdf5')\n",
    "sim2.UpdateParams(load_weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs before running: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "WARNING: At the current state, we are taking the default weight initialization, whatever it is. This must change in order to have better control.\n",
      "Train on 112 samples, validate on 49 samples\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 1.2489 - accuracy: 0.4554 - val_loss: 1.4060 - val_accuracy: 0.4082\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.2274 - accuracy: 0.4554 - val_loss: 1.4034 - val_accuracy: 0.4082\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.2082 - accuracy: 0.4554 - val_loss: 1.4009 - val_accuracy: 0.4082\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.1901 - accuracy: 0.4554 - val_loss: 1.3984 - val_accuracy: 0.4082\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.1724 - accuracy: 0.4554 - val_loss: 1.3961 - val_accuracy: 0.4082\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.1577 - accuracy: 0.4554 - val_loss: 1.3936 - val_accuracy: 0.4082\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.1441 - accuracy: 0.4554 - val_loss: 1.3914 - val_accuracy: 0.4082\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.1325 - accuracy: 0.4554 - val_loss: 1.3890 - val_accuracy: 0.4082\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.1198 - accuracy: 0.4554 - val_loss: 1.3868 - val_accuracy: 0.4082\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.1084 - accuracy: 0.4554 - val_loss: 1.3846 - val_accuracy: 0.4082\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.4554 - val_loss: 1.3824 - val_accuracy: 0.4082\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0895 - accuracy: 0.4554 - val_loss: 1.3802 - val_accuracy: 0.4082\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0819 - accuracy: 0.4554 - val_loss: 1.3781 - val_accuracy: 0.4082\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0714 - accuracy: 0.4554 - val_loss: 1.3762 - val_accuracy: 0.4082\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0655 - accuracy: 0.4554 - val_loss: 1.3741 - val_accuracy: 0.4082\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0575 - accuracy: 0.4554 - val_loss: 1.3719 - val_accuracy: 0.4082\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0505 - accuracy: 0.4554 - val_loss: 1.3697 - val_accuracy: 0.4082\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0452 - accuracy: 0.4554 - val_loss: 1.3675 - val_accuracy: 0.4082\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0368 - accuracy: 0.4554 - val_loss: 1.3655 - val_accuracy: 0.4082\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 1.0314 - accuracy: 0.4554 - val_loss: 1.3635 - val_accuracy: 0.4082\n",
      "Training took 0.14855782588322958 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n",
      "Epochs after running: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print('Epochs before running:', sim.history.epoch)\n",
    "sim2.Train()\n",
    "print('Epochs after running:', sim2.history.epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use second model to predict on new, unseen data\n",
    "Choose a class from the ones the classifier can recognize, and see whether the model is able to recognize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We only do this for 'image' models, because the format of the validation directory is wrong and I don't want to cope with that now\n",
    "if ttkind == 'image':\n",
    "    target = sim2.params.class_select[1]\n",
    "    print('target:',target)\n",
    "\n",
    "    testdir = 'data/1_zooplankton_0p5x/validation/tommy_validation/images/'+target\n",
    "    im_names=np.array(glob.glob(testdir+'/*.jpeg'),dtype=object)\n",
    "    npimages=hd.LoadImageList(im_names, L=sim2.params.L, show=False)\n",
    "\n",
    "    probs=sim2.model.predict(npimages)\n",
    "    predictions=probs.argmax(axis=1)  # The class that the classifier would bet on\n",
    "\n",
    "    print('Predictions:',sim2.tt.lb.classes_[predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
