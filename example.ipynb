{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running /opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py ['-f', '/home/marco/.local/share/jupyter/runtime/kernel-b9138dc2-9bfd-4ab5-8555-ecc9431f6765.json']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import train as t\n",
    "from src import helper_models as hm, helper_data as hd, helper_tts as htts\n",
    "from importlib import reload\n",
    "import keras, glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running /opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py ['-f', '/home/marco/.local/share/jupyter/runtime/kernel-b9138dc2-9bfd-4ab5-8555-ecc9431f6765.json']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'src.helper_tts' from '/mnt/volume2Tb/Dropbox/PROJECTS/MACHINE-LEARNING/AQUASCOPE/plankifier/src/helper_tts.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload imports of custom modules, in case I am modifying and reloading them live\n",
    "reload(t)\n",
    "reload(hd)\n",
    "reload(hm)\n",
    "reload(htts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(L=128, aug=False, bs=32, class_select=None, datakind='mixed', datapath='./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28//', dropout=None, earlyStopping=100, initial_epoch=0, layers=[256, 128], load=None, lr=5e-05, model='mlp', model_feat='mlp', model_image='mlp', opt='sgd', outpath='./out//', plot=False, saveModelName='keras_model.h5', testSplit=0.2, totEpochs=5, training_data=True, ttkind='mixed', verbose=False)\n"
     ]
    }
   ],
   "source": [
    "sim=t.Ctrain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init parameters\n",
    "Parameters must always be updated through the `UpdateParams()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.UpdateParams(\n",
    "    outpath='out_example', \n",
    "    L=128, \n",
    "    model='conv2', \n",
    "    aug=True, \n",
    "    datakind='image', \n",
    "    ttkind='image',\n",
    "    class_select=None #['chaoborus','bosmina','unknown_plankton']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output directory only after you've set the right `outpath`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.CreateOutDir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapath: ./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28//\n",
      "classes from datapath: ['kellikottia', 'filament', 'ceratium', 'chaoborus', 'fragilaria', 'dirt', 'daphnia', 'cyclops', 'conochilus', 'leptodora', 'uroglena', 'unknown', 'diaphanosoma', 'bosmina', 'fish', 'asterionella', 'paradileptus', 'keratella_quadrata', 'keratella_cochlearis', 'asplanchna', 'rotifers', 'eudiaptomus', 'trichocerca', 'nauplius', 'maybe_cyano', 'dinobryon', 'unknown_plankton']\n",
      "class: kellikottia (176)\n",
      "class: filament (204)\n",
      "class: ceratium (224)\n",
      "class: chaoborus (5)\n",
      "class: fragilaria (213)\n",
      "class: dirt (103)\n",
      "class: daphnia (522)\n",
      "class: cyclops (569)\n",
      "class: conochilus (64)\n",
      "class: leptodora (196)\n",
      "class: uroglena (872)\n",
      "class: unknown (147)\n",
      "class: diaphanosoma (1089)\n",
      "class: bosmina (48)\n",
      "class: fish (159)\n",
      "class: asterionella (171)\n",
      "class: paradileptus (70)\n",
      "class: keratella_quadrata (227)\n",
      "class: keratella_cochlearis (101)\n",
      "class: asplanchna (321)\n",
      "class: rotifers (155)\n",
      "class: eudiaptomus (372)\n",
      "class: trichocerca (243)\n",
      "class: nauplius (903)\n",
      "class: maybe_cyano (164)\n",
      "class: dinobryon (2928)\n",
      "class: unknown_plankton (47)\n"
     ]
    }
   ],
   "source": [
    "# These arguments are the defaults\n",
    "sim.LoadData(L=sim.params.L, class_select=sim.params.class_select, datakind=sim.params.datakind) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sets (test and train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.CreateTrainTestSets(ttkind=sim.params.ttkind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Model\n",
    "Custom parameter changes are made by acting directly on the params class through the `UpdateParams()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "At the current state, we are taking the default initialization, whatever it is. This must change.\n",
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "257/257 [==============================] - 22s 85ms/step - loss: 2.3443 - accuracy: 0.3436 - val_loss: 2.8735 - val_accuracy: 0.3929\n",
      "Epoch 2/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 2.0193 - accuracy: 0.4090 - val_loss: 2.1653 - val_accuracy: 0.4347\n",
      "Epoch 3/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 1.8797 - accuracy: 0.4453 - val_loss: 1.8280 - val_accuracy: 0.4672\n",
      "Epoch 4/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 1.7779 - accuracy: 0.4777 - val_loss: 1.7251 - val_accuracy: 0.5075\n",
      "Epoch 5/1000\n",
      "257/257 [==============================] - 19s 76ms/step - loss: 1.6950 - accuracy: 0.5040 - val_loss: 1.6419 - val_accuracy: 0.5367\n",
      "Epoch 6/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 1.6263 - accuracy: 0.5235 - val_loss: 1.5776 - val_accuracy: 0.5372\n",
      "Epoch 7/1000\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 1.5573 - accuracy: 0.5505 - val_loss: 1.5224 - val_accuracy: 0.5566\n",
      "Epoch 8/1000\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 1.5054 - accuracy: 0.5579 - val_loss: 1.4767 - val_accuracy: 0.5712\n",
      "Epoch 9/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 1.4440 - accuracy: 0.5780 - val_loss: 1.4182 - val_accuracy: 0.5940\n",
      "Epoch 10/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 1.3962 - accuracy: 0.5922 - val_loss: 1.3802 - val_accuracy: 0.5920\n",
      "Epoch 11/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 1.3517 - accuracy: 0.6061 - val_loss: 1.3361 - val_accuracy: 0.6221\n",
      "Epoch 12/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.3072 - accuracy: 0.6244 - val_loss: 1.2780 - val_accuracy: 0.6391\n",
      "Epoch 13/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.2715 - accuracy: 0.6348 - val_loss: 1.2508 - val_accuracy: 0.6450\n",
      "Epoch 14/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.2241 - accuracy: 0.6468 - val_loss: 1.2178 - val_accuracy: 0.6717\n",
      "Epoch 15/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.1937 - accuracy: 0.6556 - val_loss: 1.1903 - val_accuracy: 0.6557\n",
      "Epoch 16/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.1636 - accuracy: 0.6631 - val_loss: 1.1621 - val_accuracy: 0.6877\n",
      "Epoch 17/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.1400 - accuracy: 0.6782 - val_loss: 1.1398 - val_accuracy: 0.6799\n",
      "Epoch 18/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.1060 - accuracy: 0.6917 - val_loss: 1.1114 - val_accuracy: 0.6916\n",
      "Epoch 19/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.0874 - accuracy: 0.6924 - val_loss: 1.0857 - val_accuracy: 0.7037\n",
      "Epoch 20/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.0561 - accuracy: 0.7014 - val_loss: 1.0638 - val_accuracy: 0.7096\n",
      "Epoch 21/1000\n",
      "257/257 [==============================] - 20s 79ms/step - loss: 1.0468 - accuracy: 0.7067 - val_loss: 1.0524 - val_accuracy: 0.7246\n",
      "Epoch 22/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 1.0196 - accuracy: 0.7160 - val_loss: 1.0461 - val_accuracy: 0.7013\n",
      "Epoch 23/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 1.0073 - accuracy: 0.7130 - val_loss: 1.0224 - val_accuracy: 0.7227\n",
      "Epoch 24/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.9837 - accuracy: 0.7198 - val_loss: 1.0037 - val_accuracy: 0.7334\n",
      "Epoch 25/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.9611 - accuracy: 0.7268 - val_loss: 1.0041 - val_accuracy: 0.7377\n",
      "Epoch 26/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.9576 - accuracy: 0.7292 - val_loss: 0.9700 - val_accuracy: 0.7460\n",
      "Epoch 27/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.9454 - accuracy: 0.7343 - val_loss: 0.9645 - val_accuracy: 0.7441\n",
      "Epoch 28/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.9225 - accuracy: 0.7438 - val_loss: 0.9705 - val_accuracy: 0.7295\n",
      "Epoch 29/1000\n",
      "257/257 [==============================] - 20s 78ms/step - loss: 0.9172 - accuracy: 0.7428 - val_loss: 0.9293 - val_accuracy: 0.7441\n",
      "Epoch 30/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.9173 - accuracy: 0.7405 - val_loss: 0.9248 - val_accuracy: 0.7547\n",
      "Epoch 31/1000\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.8910 - accuracy: 0.7510 - val_loss: 0.9165 - val_accuracy: 0.7547\n",
      "Epoch 32/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.8785 - accuracy: 0.7540 - val_loss: 0.9189 - val_accuracy: 0.7533\n",
      "Epoch 33/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.8720 - accuracy: 0.7553 - val_loss: 0.8934 - val_accuracy: 0.7610\n",
      "Epoch 34/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.8641 - accuracy: 0.7586 - val_loss: 0.8880 - val_accuracy: 0.7572\n",
      "Epoch 35/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.8501 - accuracy: 0.7599 - val_loss: 0.8853 - val_accuracy: 0.7674\n",
      "Epoch 36/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.8469 - accuracy: 0.7641 - val_loss: 0.8704 - val_accuracy: 0.7669\n",
      "Epoch 37/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.8502 - accuracy: 0.7609 - val_loss: 0.8614 - val_accuracy: 0.7746\n",
      "Epoch 38/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.8011 - accuracy: 0.7763 - val_loss: 0.8545 - val_accuracy: 0.7810\n",
      "Epoch 39/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.8335 - accuracy: 0.7678 - val_loss: 0.8557 - val_accuracy: 0.7727\n",
      "Epoch 40/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.8061 - accuracy: 0.7718 - val_loss: 0.8525 - val_accuracy: 0.7751\n",
      "Epoch 41/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.7997 - accuracy: 0.7749 - val_loss: 0.8543 - val_accuracy: 0.7722\n",
      "Epoch 42/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7804 - accuracy: 0.7800 - val_loss: 0.8305 - val_accuracy: 0.7717\n",
      "Epoch 43/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.8027 - accuracy: 0.7744 - val_loss: 0.8116 - val_accuracy: 0.7800\n",
      "Epoch 44/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7862 - accuracy: 0.7797 - val_loss: 0.8090 - val_accuracy: 0.7858\n",
      "Epoch 45/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7695 - accuracy: 0.7836 - val_loss: 0.8216 - val_accuracy: 0.7698\n",
      "Epoch 46/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7596 - accuracy: 0.7841 - val_loss: 0.7938 - val_accuracy: 0.7848\n",
      "Epoch 47/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.7653 - accuracy: 0.7847 - val_loss: 0.7962 - val_accuracy: 0.7863\n",
      "Epoch 48/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7852 - accuracy: 0.7788 - val_loss: 0.8061 - val_accuracy: 0.7703\n",
      "Epoch 49/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.7353 - accuracy: 0.7891 - val_loss: 0.7713 - val_accuracy: 0.7980\n",
      "Epoch 50/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7504 - accuracy: 0.7874 - val_loss: 0.7749 - val_accuracy: 0.7950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7402 - accuracy: 0.7866 - val_loss: 0.7581 - val_accuracy: 0.7946\n",
      "Epoch 52/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7378 - accuracy: 0.7881 - val_loss: 0.7572 - val_accuracy: 0.7970\n",
      "Epoch 53/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7219 - accuracy: 0.7949 - val_loss: 0.7518 - val_accuracy: 0.7984\n",
      "Epoch 54/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.7209 - accuracy: 0.7950 - val_loss: 0.7495 - val_accuracy: 0.8014\n",
      "Epoch 55/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7151 - accuracy: 0.7969 - val_loss: 0.7528 - val_accuracy: 0.7989\n",
      "Epoch 56/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.7162 - accuracy: 0.7959 - val_loss: 0.7464 - val_accuracy: 0.7994\n",
      "Epoch 57/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6987 - accuracy: 0.8058 - val_loss: 0.7403 - val_accuracy: 0.7984\n",
      "Epoch 58/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.7185 - accuracy: 0.7990 - val_loss: 0.7402 - val_accuracy: 0.8009\n",
      "Epoch 59/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6966 - accuracy: 0.8026 - val_loss: 0.7482 - val_accuracy: 0.7999\n",
      "Epoch 60/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6953 - accuracy: 0.8029 - val_loss: 0.7253 - val_accuracy: 0.8028\n",
      "Epoch 61/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6875 - accuracy: 0.8046 - val_loss: 0.7156 - val_accuracy: 0.8125\n",
      "Epoch 62/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6831 - accuracy: 0.8079 - val_loss: 0.7116 - val_accuracy: 0.8086\n",
      "Epoch 63/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6850 - accuracy: 0.8100 - val_loss: 0.7001 - val_accuracy: 0.8145\n",
      "Epoch 64/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6798 - accuracy: 0.8081 - val_loss: 0.7257 - val_accuracy: 0.8057\n",
      "Epoch 65/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6682 - accuracy: 0.8102 - val_loss: 0.7061 - val_accuracy: 0.8150\n",
      "Epoch 66/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6704 - accuracy: 0.8090 - val_loss: 0.7003 - val_accuracy: 0.8154\n",
      "Epoch 67/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6662 - accuracy: 0.8152 - val_loss: 0.6861 - val_accuracy: 0.8179\n",
      "Epoch 68/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6444 - accuracy: 0.8172 - val_loss: 0.7306 - val_accuracy: 0.7980\n",
      "Epoch 69/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6665 - accuracy: 0.8102 - val_loss: 0.6839 - val_accuracy: 0.8184\n",
      "Epoch 70/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6562 - accuracy: 0.8151 - val_loss: 0.6815 - val_accuracy: 0.8159\n",
      "Epoch 71/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6391 - accuracy: 0.8177 - val_loss: 0.6753 - val_accuracy: 0.8159\n",
      "Epoch 72/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6531 - accuracy: 0.8150 - val_loss: 0.6872 - val_accuracy: 0.8188\n",
      "Epoch 73/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6345 - accuracy: 0.8211 - val_loss: 0.6825 - val_accuracy: 0.8150\n",
      "Epoch 74/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6434 - accuracy: 0.8175 - val_loss: 0.6701 - val_accuracy: 0.8232\n",
      "Epoch 75/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6436 - accuracy: 0.8187 - val_loss: 0.6641 - val_accuracy: 0.8227\n",
      "Epoch 76/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6392 - accuracy: 0.8188 - val_loss: 0.6693 - val_accuracy: 0.8145\n",
      "Epoch 77/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6302 - accuracy: 0.8185 - val_loss: 0.6713 - val_accuracy: 0.8116\n",
      "Epoch 78/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6202 - accuracy: 0.8217 - val_loss: 0.6624 - val_accuracy: 0.8179\n",
      "Epoch 79/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6252 - accuracy: 0.8225 - val_loss: 0.6537 - val_accuracy: 0.8247\n",
      "Epoch 80/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6032 - accuracy: 0.8299 - val_loss: 0.6493 - val_accuracy: 0.8232\n",
      "Epoch 81/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6246 - accuracy: 0.8211 - val_loss: 0.6466 - val_accuracy: 0.8252\n",
      "Epoch 82/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6193 - accuracy: 0.8233 - val_loss: 0.6494 - val_accuracy: 0.8232\n",
      "Epoch 83/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6086 - accuracy: 0.8243 - val_loss: 0.6483 - val_accuracy: 0.8218\n",
      "Epoch 84/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6031 - accuracy: 0.8308 - val_loss: 0.6334 - val_accuracy: 0.8315\n",
      "Epoch 85/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6067 - accuracy: 0.8271 - val_loss: 0.6338 - val_accuracy: 0.8295\n",
      "Epoch 86/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6144 - accuracy: 0.8236 - val_loss: 0.6351 - val_accuracy: 0.8256\n",
      "Epoch 87/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5929 - accuracy: 0.8292 - val_loss: 0.6230 - val_accuracy: 0.8310\n",
      "Epoch 88/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6016 - accuracy: 0.8247 - val_loss: 0.6241 - val_accuracy: 0.8300\n",
      "Epoch 89/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5853 - accuracy: 0.8314 - val_loss: 0.6226 - val_accuracy: 0.8315\n",
      "Epoch 90/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5876 - accuracy: 0.8322 - val_loss: 0.6525 - val_accuracy: 0.8198\n",
      "Epoch 91/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6012 - accuracy: 0.8269 - val_loss: 0.6271 - val_accuracy: 0.8286\n",
      "Epoch 92/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5849 - accuracy: 0.8313 - val_loss: 0.6147 - val_accuracy: 0.8295\n",
      "Epoch 93/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5856 - accuracy: 0.8322 - val_loss: 0.6142 - val_accuracy: 0.8315\n",
      "Epoch 94/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5781 - accuracy: 0.8364 - val_loss: 0.6138 - val_accuracy: 0.8344\n",
      "Epoch 95/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5814 - accuracy: 0.8320 - val_loss: 0.6050 - val_accuracy: 0.8373\n",
      "Epoch 96/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5710 - accuracy: 0.8358 - val_loss: 0.6297 - val_accuracy: 0.8261\n",
      "Epoch 97/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5682 - accuracy: 0.8377 - val_loss: 0.5994 - val_accuracy: 0.8402\n",
      "Epoch 98/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5830 - accuracy: 0.8351 - val_loss: 0.6201 - val_accuracy: 0.8266\n",
      "Epoch 99/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5749 - accuracy: 0.8372 - val_loss: 0.5968 - val_accuracy: 0.8383\n",
      "Epoch 100/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5587 - accuracy: 0.8447 - val_loss: 0.6024 - val_accuracy: 0.8388\n",
      "Epoch 101/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5706 - accuracy: 0.8357 - val_loss: 0.5980 - val_accuracy: 0.8349\n",
      "Epoch 102/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5576 - accuracy: 0.8385 - val_loss: 0.6321 - val_accuracy: 0.8203\n",
      "Epoch 103/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5590 - accuracy: 0.8421 - val_loss: 0.5953 - val_accuracy: 0.8388\n",
      "Epoch 104/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5619 - accuracy: 0.8374 - val_loss: 0.5896 - val_accuracy: 0.8368\n",
      "Epoch 105/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5506 - accuracy: 0.8403 - val_loss: 0.5964 - val_accuracy: 0.8349\n",
      "Epoch 106/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5558 - accuracy: 0.8385 - val_loss: 0.6325 - val_accuracy: 0.8290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5407 - accuracy: 0.8482 - val_loss: 0.6082 - val_accuracy: 0.8320\n",
      "Epoch 108/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5661 - accuracy: 0.8392 - val_loss: 0.6199 - val_accuracy: 0.8232\n",
      "Epoch 109/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5350 - accuracy: 0.8469 - val_loss: 0.5908 - val_accuracy: 0.8392\n",
      "Epoch 110/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5423 - accuracy: 0.8446 - val_loss: 0.5699 - val_accuracy: 0.8465\n",
      "Epoch 111/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5475 - accuracy: 0.8442 - val_loss: 0.5777 - val_accuracy: 0.8426\n",
      "Epoch 112/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5365 - accuracy: 0.8434 - val_loss: 0.5769 - val_accuracy: 0.8441\n",
      "Epoch 113/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5415 - accuracy: 0.8454 - val_loss: 0.5699 - val_accuracy: 0.8446\n",
      "Epoch 114/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5403 - accuracy: 0.8449 - val_loss: 0.5734 - val_accuracy: 0.8349\n",
      "Epoch 115/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5358 - accuracy: 0.8435 - val_loss: 0.5729 - val_accuracy: 0.8402\n",
      "Epoch 116/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5288 - accuracy: 0.8465 - val_loss: 0.5932 - val_accuracy: 0.8315\n",
      "Epoch 117/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5192 - accuracy: 0.8512 - val_loss: 0.5735 - val_accuracy: 0.8407\n",
      "Epoch 118/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5396 - accuracy: 0.8432 - val_loss: 0.5748 - val_accuracy: 0.8373\n",
      "Epoch 119/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5230 - accuracy: 0.8515 - val_loss: 0.5693 - val_accuracy: 0.8465\n",
      "Epoch 120/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5252 - accuracy: 0.8491 - val_loss: 0.5713 - val_accuracy: 0.8378\n",
      "Epoch 121/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5277 - accuracy: 0.8495 - val_loss: 0.5614 - val_accuracy: 0.8426\n",
      "Epoch 122/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5089 - accuracy: 0.8515 - val_loss: 0.5506 - val_accuracy: 0.8509\n",
      "Epoch 123/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5134 - accuracy: 0.8519 - val_loss: 0.5586 - val_accuracy: 0.8441\n",
      "Epoch 124/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5315 - accuracy: 0.8456 - val_loss: 0.5598 - val_accuracy: 0.8402\n",
      "Epoch 125/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5235 - accuracy: 0.8486 - val_loss: 0.5582 - val_accuracy: 0.8456\n",
      "Epoch 126/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.4953 - accuracy: 0.8541 - val_loss: 0.5659 - val_accuracy: 0.8363\n",
      "Epoch 127/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5203 - accuracy: 0.8501 - val_loss: 0.5446 - val_accuracy: 0.8441\n",
      "Epoch 128/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5039 - accuracy: 0.8536 - val_loss: 0.5480 - val_accuracy: 0.8456\n",
      "Epoch 129/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5004 - accuracy: 0.8532 - val_loss: 0.5369 - val_accuracy: 0.8524\n",
      "Epoch 130/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5147 - accuracy: 0.8509 - val_loss: 0.5311 - val_accuracy: 0.8577\n",
      "Epoch 131/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5018 - accuracy: 0.8519 - val_loss: 0.5511 - val_accuracy: 0.8470\n",
      "Epoch 132/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.4973 - accuracy: 0.8609 - val_loss: 0.5406 - val_accuracy: 0.8480\n",
      "Epoch 133/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.4969 - accuracy: 0.8574 - val_loss: 0.5564 - val_accuracy: 0.8426\n",
      "Epoch 134/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4905 - accuracy: 0.8576 - val_loss: 0.5268 - val_accuracy: 0.8519\n",
      "Epoch 135/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5064 - accuracy: 0.8541 - val_loss: 0.5323 - val_accuracy: 0.8509\n",
      "Epoch 136/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.5045 - accuracy: 0.8554 - val_loss: 0.5284 - val_accuracy: 0.8524\n",
      "Epoch 137/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.4804 - accuracy: 0.8613 - val_loss: 0.5387 - val_accuracy: 0.8470\n",
      "Epoch 138/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.5022 - accuracy: 0.8538 - val_loss: 0.5577 - val_accuracy: 0.8446\n",
      "Epoch 139/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4958 - accuracy: 0.8582 - val_loss: 0.5302 - val_accuracy: 0.8553\n",
      "Epoch 140/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4916 - accuracy: 0.8574 - val_loss: 0.5390 - val_accuracy: 0.8480\n",
      "Epoch 141/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4818 - accuracy: 0.8578 - val_loss: 0.5348 - val_accuracy: 0.8528\n",
      "Epoch 142/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4965 - accuracy: 0.8537 - val_loss: 0.5233 - val_accuracy: 0.8524\n",
      "Epoch 143/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4825 - accuracy: 0.8613 - val_loss: 0.5615 - val_accuracy: 0.8388\n",
      "Epoch 144/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4842 - accuracy: 0.8549 - val_loss: 0.5639 - val_accuracy: 0.8412\n",
      "Epoch 145/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4788 - accuracy: 0.8686 - val_loss: 0.5186 - val_accuracy: 0.8509\n",
      "Epoch 146/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4831 - accuracy: 0.8582 - val_loss: 0.5241 - val_accuracy: 0.8509\n",
      "Epoch 147/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4697 - accuracy: 0.8645 - val_loss: 0.5186 - val_accuracy: 0.8567\n",
      "Epoch 148/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4801 - accuracy: 0.8587 - val_loss: 0.5109 - val_accuracy: 0.8572\n",
      "Epoch 149/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4778 - accuracy: 0.8611 - val_loss: 0.5206 - val_accuracy: 0.8504\n",
      "Epoch 150/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4766 - accuracy: 0.8628 - val_loss: 0.5087 - val_accuracy: 0.8567\n",
      "Epoch 151/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4777 - accuracy: 0.8608 - val_loss: 0.5483 - val_accuracy: 0.8412\n",
      "Epoch 152/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4699 - accuracy: 0.8637 - val_loss: 0.5556 - val_accuracy: 0.8431\n",
      "Epoch 153/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4690 - accuracy: 0.8631 - val_loss: 0.5123 - val_accuracy: 0.8538\n",
      "Epoch 154/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4664 - accuracy: 0.8638 - val_loss: 0.5247 - val_accuracy: 0.8543\n",
      "Epoch 155/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4726 - accuracy: 0.8601 - val_loss: 0.5077 - val_accuracy: 0.8528\n",
      "Epoch 156/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4714 - accuracy: 0.8643 - val_loss: 0.4971 - val_accuracy: 0.8601\n",
      "Epoch 157/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4605 - accuracy: 0.8659 - val_loss: 0.5012 - val_accuracy: 0.8582\n",
      "Epoch 158/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4616 - accuracy: 0.8631 - val_loss: 0.5000 - val_accuracy: 0.8562\n",
      "Epoch 159/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4740 - accuracy: 0.8610 - val_loss: 0.5108 - val_accuracy: 0.8519\n",
      "Epoch 160/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4602 - accuracy: 0.8665 - val_loss: 0.5159 - val_accuracy: 0.8524\n",
      "Epoch 161/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4570 - accuracy: 0.8710 - val_loss: 0.4945 - val_accuracy: 0.8587\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4560 - accuracy: 0.8730 - val_loss: 0.5006 - val_accuracy: 0.8548\n",
      "Epoch 163/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4654 - accuracy: 0.8650 - val_loss: 0.4965 - val_accuracy: 0.8611\n",
      "Epoch 164/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4571 - accuracy: 0.8680 - val_loss: 0.5318 - val_accuracy: 0.8446\n",
      "Epoch 165/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4590 - accuracy: 0.8666 - val_loss: 0.5071 - val_accuracy: 0.8475\n",
      "Epoch 166/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4584 - accuracy: 0.8703 - val_loss: 0.4866 - val_accuracy: 0.8630\n",
      "Epoch 167/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4518 - accuracy: 0.8688 - val_loss: 0.4876 - val_accuracy: 0.8606\n",
      "Epoch 168/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4407 - accuracy: 0.8724 - val_loss: 0.4866 - val_accuracy: 0.8616\n",
      "Epoch 169/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4584 - accuracy: 0.8665 - val_loss: 0.4925 - val_accuracy: 0.8616\n",
      "Epoch 170/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4467 - accuracy: 0.8715 - val_loss: 0.5025 - val_accuracy: 0.8538\n",
      "Epoch 171/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4456 - accuracy: 0.8699 - val_loss: 0.5008 - val_accuracy: 0.8543\n",
      "Epoch 172/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4519 - accuracy: 0.8677 - val_loss: 0.4832 - val_accuracy: 0.8601\n",
      "Epoch 173/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4477 - accuracy: 0.8691 - val_loss: 0.5311 - val_accuracy: 0.8524\n",
      "Epoch 174/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4345 - accuracy: 0.8733 - val_loss: 0.4910 - val_accuracy: 0.8626\n",
      "Epoch 175/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4442 - accuracy: 0.8671 - val_loss: 0.4971 - val_accuracy: 0.8553\n",
      "Epoch 176/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4352 - accuracy: 0.8754 - val_loss: 0.5007 - val_accuracy: 0.8567\n",
      "Epoch 177/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4448 - accuracy: 0.8692 - val_loss: 0.4864 - val_accuracy: 0.8567\n",
      "Epoch 178/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4351 - accuracy: 0.8732 - val_loss: 0.4782 - val_accuracy: 0.8645\n",
      "Epoch 179/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4562 - accuracy: 0.8649 - val_loss: 0.4915 - val_accuracy: 0.8582\n",
      "Epoch 180/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4308 - accuracy: 0.8725 - val_loss: 0.4811 - val_accuracy: 0.8664\n",
      "Epoch 181/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4475 - accuracy: 0.8720 - val_loss: 0.4730 - val_accuracy: 0.8660\n",
      "Epoch 182/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4481 - accuracy: 0.8688 - val_loss: 0.4805 - val_accuracy: 0.8650\n",
      "Epoch 183/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4253 - accuracy: 0.8739 - val_loss: 0.4794 - val_accuracy: 0.8635\n",
      "Epoch 184/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4364 - accuracy: 0.8749 - val_loss: 0.4890 - val_accuracy: 0.8611\n",
      "Epoch 185/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4328 - accuracy: 0.8755 - val_loss: 0.4741 - val_accuracy: 0.8626\n",
      "Epoch 186/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4288 - accuracy: 0.8773 - val_loss: 0.4757 - val_accuracy: 0.8606\n",
      "Epoch 187/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4389 - accuracy: 0.8711 - val_loss: 0.4878 - val_accuracy: 0.8611\n",
      "Epoch 188/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4246 - accuracy: 0.8792 - val_loss: 0.4645 - val_accuracy: 0.8684\n",
      "Epoch 189/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4243 - accuracy: 0.8733 - val_loss: 0.4944 - val_accuracy: 0.8524\n",
      "Epoch 190/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4288 - accuracy: 0.8728 - val_loss: 0.4698 - val_accuracy: 0.8640\n",
      "Epoch 191/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4224 - accuracy: 0.8738 - val_loss: 0.4775 - val_accuracy: 0.8572\n",
      "Epoch 192/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4132 - accuracy: 0.8810 - val_loss: 0.4901 - val_accuracy: 0.8601\n",
      "Epoch 193/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4231 - accuracy: 0.8793 - val_loss: 0.4651 - val_accuracy: 0.8679\n",
      "Epoch 194/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4250 - accuracy: 0.8773 - val_loss: 0.4830 - val_accuracy: 0.8650\n",
      "Epoch 195/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4301 - accuracy: 0.8754 - val_loss: 0.4617 - val_accuracy: 0.8723\n",
      "Epoch 196/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4113 - accuracy: 0.8775 - val_loss: 0.4871 - val_accuracy: 0.8596\n",
      "Epoch 197/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4255 - accuracy: 0.8753 - val_loss: 0.4722 - val_accuracy: 0.8669\n",
      "Epoch 198/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4252 - accuracy: 0.8725 - val_loss: 0.4711 - val_accuracy: 0.8606\n",
      "Epoch 199/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4129 - accuracy: 0.8793 - val_loss: 0.4641 - val_accuracy: 0.8626\n",
      "Epoch 200/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4308 - accuracy: 0.8752 - val_loss: 0.4651 - val_accuracy: 0.8621\n",
      "Epoch 201/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4122 - accuracy: 0.8759 - val_loss: 0.4692 - val_accuracy: 0.8645\n",
      "Epoch 202/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4228 - accuracy: 0.8793 - val_loss: 0.4744 - val_accuracy: 0.8592\n",
      "Epoch 203/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4140 - accuracy: 0.8802 - val_loss: 0.4740 - val_accuracy: 0.8640\n",
      "Epoch 204/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4062 - accuracy: 0.8793 - val_loss: 0.4682 - val_accuracy: 0.8630\n",
      "Epoch 205/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4220 - accuracy: 0.8756 - val_loss: 0.4617 - val_accuracy: 0.8664\n",
      "Epoch 206/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4131 - accuracy: 0.8758 - val_loss: 0.4633 - val_accuracy: 0.8660\n",
      "Epoch 207/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4088 - accuracy: 0.8813 - val_loss: 0.4614 - val_accuracy: 0.8689\n",
      "Epoch 208/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4049 - accuracy: 0.8842 - val_loss: 0.4725 - val_accuracy: 0.8630\n",
      "Epoch 209/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3944 - accuracy: 0.8850 - val_loss: 0.4503 - val_accuracy: 0.8718\n",
      "Epoch 210/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4115 - accuracy: 0.8789 - val_loss: 0.4479 - val_accuracy: 0.8742\n",
      "Epoch 211/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4159 - accuracy: 0.8812 - val_loss: 0.4739 - val_accuracy: 0.8596\n",
      "Epoch 212/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4013 - accuracy: 0.8817 - val_loss: 0.4904 - val_accuracy: 0.8587\n",
      "Epoch 213/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4059 - accuracy: 0.8797 - val_loss: 0.4633 - val_accuracy: 0.8635\n",
      "Epoch 214/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3998 - accuracy: 0.8826 - val_loss: 0.4685 - val_accuracy: 0.8621\n",
      "Epoch 215/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4087 - accuracy: 0.8852 - val_loss: 0.4797 - val_accuracy: 0.8621\n",
      "Epoch 216/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3990 - accuracy: 0.8817 - val_loss: 0.4479 - val_accuracy: 0.8689\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3952 - accuracy: 0.8828 - val_loss: 0.4774 - val_accuracy: 0.8664\n",
      "Epoch 218/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4019 - accuracy: 0.8820 - val_loss: 0.4747 - val_accuracy: 0.8567\n",
      "Epoch 219/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3945 - accuracy: 0.8855 - val_loss: 0.4581 - val_accuracy: 0.8660\n",
      "Epoch 220/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4027 - accuracy: 0.8831 - val_loss: 0.4516 - val_accuracy: 0.8698\n",
      "Epoch 221/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4063 - accuracy: 0.8812 - val_loss: 0.4548 - val_accuracy: 0.8723\n",
      "Epoch 222/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3906 - accuracy: 0.8858 - val_loss: 0.4471 - val_accuracy: 0.8684\n",
      "Epoch 223/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4045 - accuracy: 0.8812 - val_loss: 0.4579 - val_accuracy: 0.8650\n",
      "Epoch 224/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3992 - accuracy: 0.8854 - val_loss: 0.4477 - val_accuracy: 0.8728\n",
      "Epoch 225/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3900 - accuracy: 0.8854 - val_loss: 0.4568 - val_accuracy: 0.8698\n",
      "Epoch 226/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3926 - accuracy: 0.8862 - val_loss: 0.4510 - val_accuracy: 0.8718\n",
      "Epoch 227/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3986 - accuracy: 0.8822 - val_loss: 0.4332 - val_accuracy: 0.8776\n",
      "Epoch 228/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3793 - accuracy: 0.8882 - val_loss: 0.4331 - val_accuracy: 0.8762\n",
      "Epoch 229/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.4009 - accuracy: 0.8830 - val_loss: 0.4458 - val_accuracy: 0.8694\n",
      "Epoch 230/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3900 - accuracy: 0.8830 - val_loss: 0.4299 - val_accuracy: 0.8762\n",
      "Epoch 231/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3906 - accuracy: 0.8849 - val_loss: 0.4345 - val_accuracy: 0.8752\n",
      "Epoch 232/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3904 - accuracy: 0.8862 - val_loss: 0.4442 - val_accuracy: 0.8752\n",
      "Epoch 233/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3855 - accuracy: 0.8872 - val_loss: 0.4523 - val_accuracy: 0.8718\n",
      "Epoch 234/1000\n",
      "257/257 [==============================] - 19s 76ms/step - loss: 0.3835 - accuracy: 0.8870 - val_loss: 0.4431 - val_accuracy: 0.8684\n",
      "Epoch 235/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3860 - accuracy: 0.8864 - val_loss: 0.4410 - val_accuracy: 0.8752\n",
      "Epoch 236/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3884 - accuracy: 0.8856 - val_loss: 0.4357 - val_accuracy: 0.8766\n",
      "Epoch 237/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3826 - accuracy: 0.8855 - val_loss: 0.4417 - val_accuracy: 0.8747\n",
      "Epoch 238/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3859 - accuracy: 0.8847 - val_loss: 0.4341 - val_accuracy: 0.8786\n",
      "Epoch 239/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3822 - accuracy: 0.8844 - val_loss: 0.4406 - val_accuracy: 0.8723\n",
      "Epoch 240/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3772 - accuracy: 0.8889 - val_loss: 0.4634 - val_accuracy: 0.8650\n",
      "Epoch 241/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3810 - accuracy: 0.8873 - val_loss: 0.4290 - val_accuracy: 0.8752\n",
      "Epoch 242/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3771 - accuracy: 0.8881 - val_loss: 0.4344 - val_accuracy: 0.8771\n",
      "Epoch 243/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3814 - accuracy: 0.8856 - val_loss: 0.4338 - val_accuracy: 0.8732\n",
      "Epoch 244/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3843 - accuracy: 0.8859 - val_loss: 0.4411 - val_accuracy: 0.8713\n",
      "Epoch 245/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3732 - accuracy: 0.8887 - val_loss: 0.4367 - val_accuracy: 0.8718\n",
      "Epoch 246/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3768 - accuracy: 0.8872 - val_loss: 0.4299 - val_accuracy: 0.8771\n",
      "Epoch 247/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3733 - accuracy: 0.8897 - val_loss: 0.4591 - val_accuracy: 0.8713\n",
      "Epoch 248/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3747 - accuracy: 0.8887 - val_loss: 0.4742 - val_accuracy: 0.8640\n",
      "Epoch 249/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3739 - accuracy: 0.8882 - val_loss: 0.4350 - val_accuracy: 0.8776\n",
      "Epoch 250/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3699 - accuracy: 0.8925 - val_loss: 0.4349 - val_accuracy: 0.8742\n",
      "Epoch 251/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3689 - accuracy: 0.8917 - val_loss: 0.4128 - val_accuracy: 0.8864\n",
      "Epoch 252/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3752 - accuracy: 0.8898 - val_loss: 0.4426 - val_accuracy: 0.8684\n",
      "Epoch 253/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3741 - accuracy: 0.8884 - val_loss: 0.4202 - val_accuracy: 0.8796\n",
      "Epoch 254/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3737 - accuracy: 0.8891 - val_loss: 0.4735 - val_accuracy: 0.8616\n",
      "Epoch 255/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3694 - accuracy: 0.8917 - val_loss: 0.4206 - val_accuracy: 0.8762\n",
      "Epoch 256/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3688 - accuracy: 0.8910 - val_loss: 0.4333 - val_accuracy: 0.8766\n",
      "Epoch 257/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3687 - accuracy: 0.8888 - val_loss: 0.4156 - val_accuracy: 0.8830\n",
      "Epoch 258/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3718 - accuracy: 0.8905 - val_loss: 0.4269 - val_accuracy: 0.8742\n",
      "Epoch 259/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3605 - accuracy: 0.8930 - val_loss: 0.4078 - val_accuracy: 0.8815\n",
      "Epoch 260/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3629 - accuracy: 0.8923 - val_loss: 0.4348 - val_accuracy: 0.8718\n",
      "Epoch 261/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3631 - accuracy: 0.8906 - val_loss: 0.4643 - val_accuracy: 0.8669\n",
      "Epoch 262/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3625 - accuracy: 0.8922 - val_loss: 0.4041 - val_accuracy: 0.8844\n",
      "Epoch 263/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3677 - accuracy: 0.8892 - val_loss: 0.4120 - val_accuracy: 0.8820\n",
      "Epoch 264/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3694 - accuracy: 0.8871 - val_loss: 0.4021 - val_accuracy: 0.8849\n",
      "Epoch 265/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3566 - accuracy: 0.8943 - val_loss: 0.4150 - val_accuracy: 0.8825\n",
      "Epoch 266/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3674 - accuracy: 0.8898 - val_loss: 0.4153 - val_accuracy: 0.8776\n",
      "Epoch 267/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3645 - accuracy: 0.8930 - val_loss: 0.4193 - val_accuracy: 0.8766\n",
      "Epoch 268/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3601 - accuracy: 0.8941 - val_loss: 0.4443 - val_accuracy: 0.8728\n",
      "Epoch 269/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3626 - accuracy: 0.8954 - val_loss: 0.4650 - val_accuracy: 0.8601\n",
      "Epoch 270/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3667 - accuracy: 0.8917 - val_loss: 0.4057 - val_accuracy: 0.8834\n",
      "Epoch 271/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3567 - accuracy: 0.8960 - val_loss: 0.4025 - val_accuracy: 0.8825\n",
      "Epoch 272/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3552 - accuracy: 0.8960 - val_loss: 0.4154 - val_accuracy: 0.8825\n",
      "Epoch 273/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3579 - accuracy: 0.8956 - val_loss: 0.4531 - val_accuracy: 0.8698\n",
      "Epoch 274/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3602 - accuracy: 0.8966 - val_loss: 0.4336 - val_accuracy: 0.8771\n",
      "Epoch 275/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3505 - accuracy: 0.8955 - val_loss: 0.4116 - val_accuracy: 0.8825\n",
      "Epoch 276/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3567 - accuracy: 0.8953 - val_loss: 0.4173 - val_accuracy: 0.8771\n",
      "Epoch 277/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3581 - accuracy: 0.8950 - val_loss: 0.4431 - val_accuracy: 0.8718\n",
      "Epoch 278/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3469 - accuracy: 0.8986 - val_loss: 0.3990 - val_accuracy: 0.8864\n",
      "Epoch 279/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3547 - accuracy: 0.8953 - val_loss: 0.3982 - val_accuracy: 0.8873\n",
      "Epoch 280/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3504 - accuracy: 0.8978 - val_loss: 0.4218 - val_accuracy: 0.8834\n",
      "Epoch 281/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3575 - accuracy: 0.8950 - val_loss: 0.4580 - val_accuracy: 0.8655\n",
      "Epoch 282/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3430 - accuracy: 0.8962 - val_loss: 0.4109 - val_accuracy: 0.8820\n",
      "Epoch 283/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3517 - accuracy: 0.8980 - val_loss: 0.4304 - val_accuracy: 0.8742\n",
      "Epoch 284/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3440 - accuracy: 0.9000 - val_loss: 0.4128 - val_accuracy: 0.8805\n",
      "Epoch 285/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3562 - accuracy: 0.8948 - val_loss: 0.4022 - val_accuracy: 0.8810\n",
      "Epoch 286/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3347 - accuracy: 0.9015 - val_loss: 0.3947 - val_accuracy: 0.8859\n",
      "Epoch 287/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3462 - accuracy: 0.8971 - val_loss: 0.3990 - val_accuracy: 0.8854\n",
      "Epoch 288/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3446 - accuracy: 0.8984 - val_loss: 0.3934 - val_accuracy: 0.8873\n",
      "Epoch 289/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3495 - accuracy: 0.8981 - val_loss: 0.4073 - val_accuracy: 0.8825\n",
      "Epoch 290/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3443 - accuracy: 0.8986 - val_loss: 0.4166 - val_accuracy: 0.8810\n",
      "Epoch 291/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3404 - accuracy: 0.8977 - val_loss: 0.3982 - val_accuracy: 0.8810\n",
      "Epoch 292/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3513 - accuracy: 0.8951 - val_loss: 0.4010 - val_accuracy: 0.8854\n",
      "Epoch 293/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3326 - accuracy: 0.9039 - val_loss: 0.3925 - val_accuracy: 0.8800\n",
      "Epoch 294/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3450 - accuracy: 0.8941 - val_loss: 0.4196 - val_accuracy: 0.8781\n",
      "Epoch 295/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3449 - accuracy: 0.8981 - val_loss: 0.4035 - val_accuracy: 0.8810\n",
      "Epoch 296/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3395 - accuracy: 0.8992 - val_loss: 0.3887 - val_accuracy: 0.8902\n",
      "Epoch 297/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3443 - accuracy: 0.8970 - val_loss: 0.4114 - val_accuracy: 0.8800\n",
      "Epoch 298/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3397 - accuracy: 0.8973 - val_loss: 0.4122 - val_accuracy: 0.8786\n",
      "Epoch 299/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3434 - accuracy: 0.8980 - val_loss: 0.3893 - val_accuracy: 0.8883\n",
      "Epoch 300/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3337 - accuracy: 0.8990 - val_loss: 0.4741 - val_accuracy: 0.8587\n",
      "Epoch 301/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3396 - accuracy: 0.9011 - val_loss: 0.4276 - val_accuracy: 0.8776\n",
      "Epoch 302/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3457 - accuracy: 0.8960 - val_loss: 0.3864 - val_accuracy: 0.8883\n",
      "Epoch 303/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3344 - accuracy: 0.9028 - val_loss: 0.3814 - val_accuracy: 0.8902\n",
      "Epoch 304/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3389 - accuracy: 0.8971 - val_loss: 0.3846 - val_accuracy: 0.8878\n",
      "Epoch 305/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3336 - accuracy: 0.9012 - val_loss: 0.3896 - val_accuracy: 0.8902\n",
      "Epoch 306/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3429 - accuracy: 0.8979 - val_loss: 0.4075 - val_accuracy: 0.8786\n",
      "Epoch 307/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3335 - accuracy: 0.9013 - val_loss: 0.3927 - val_accuracy: 0.8820\n",
      "Epoch 308/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3318 - accuracy: 0.8987 - val_loss: 0.3983 - val_accuracy: 0.8820\n",
      "Epoch 309/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3366 - accuracy: 0.8986 - val_loss: 0.4190 - val_accuracy: 0.8757\n",
      "Epoch 310/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3325 - accuracy: 0.9005 - val_loss: 0.3926 - val_accuracy: 0.8796\n",
      "Epoch 311/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3388 - accuracy: 0.8990 - val_loss: 0.3882 - val_accuracy: 0.8839\n",
      "Epoch 312/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3267 - accuracy: 0.9020 - val_loss: 0.4292 - val_accuracy: 0.8815\n",
      "Epoch 313/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3230 - accuracy: 0.9044 - val_loss: 0.3882 - val_accuracy: 0.8873\n",
      "Epoch 314/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3459 - accuracy: 0.8971 - val_loss: 0.3837 - val_accuracy: 0.8912\n",
      "Epoch 315/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3271 - accuracy: 0.9064 - val_loss: 0.3866 - val_accuracy: 0.8878\n",
      "Epoch 316/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3320 - accuracy: 0.9016 - val_loss: 0.3813 - val_accuracy: 0.8859\n",
      "Epoch 317/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3305 - accuracy: 0.9027 - val_loss: 0.4005 - val_accuracy: 0.8786\n",
      "Epoch 318/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3244 - accuracy: 0.9027 - val_loss: 0.3807 - val_accuracy: 0.8922\n",
      "Epoch 319/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3268 - accuracy: 0.9043 - val_loss: 0.3847 - val_accuracy: 0.8868\n",
      "Epoch 320/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3252 - accuracy: 0.9025 - val_loss: 0.4074 - val_accuracy: 0.8815\n",
      "Epoch 321/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3278 - accuracy: 0.9026 - val_loss: 0.3855 - val_accuracy: 0.8859\n",
      "Epoch 322/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3138 - accuracy: 0.9086 - val_loss: 0.3806 - val_accuracy: 0.8873\n",
      "Epoch 323/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3214 - accuracy: 0.9032 - val_loss: 0.3811 - val_accuracy: 0.8825\n",
      "Epoch 324/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3370 - accuracy: 0.9013 - val_loss: 0.3782 - val_accuracy: 0.8917\n",
      "Epoch 325/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3249 - accuracy: 0.9031 - val_loss: 0.4097 - val_accuracy: 0.8796\n",
      "Epoch 326/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3228 - accuracy: 0.9036 - val_loss: 0.3773 - val_accuracy: 0.8902\n",
      "Epoch 327/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3265 - accuracy: 0.9062 - val_loss: 0.3655 - val_accuracy: 0.8912\n",
      "Epoch 328/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3106 - accuracy: 0.9076 - val_loss: 0.3801 - val_accuracy: 0.8912\n",
      "Epoch 329/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3230 - accuracy: 0.9053 - val_loss: 0.3831 - val_accuracy: 0.8878\n",
      "Epoch 330/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3196 - accuracy: 0.9042 - val_loss: 0.3783 - val_accuracy: 0.8878\n",
      "Epoch 331/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3175 - accuracy: 0.9066 - val_loss: 0.3858 - val_accuracy: 0.8849\n",
      "Epoch 332/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3246 - accuracy: 0.9031 - val_loss: 0.3759 - val_accuracy: 0.8854\n",
      "Epoch 333/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3216 - accuracy: 0.9014 - val_loss: 0.3779 - val_accuracy: 0.8902\n",
      "Epoch 334/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3076 - accuracy: 0.9079 - val_loss: 0.3801 - val_accuracy: 0.8873\n",
      "Epoch 335/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3272 - accuracy: 0.9032 - val_loss: 0.3747 - val_accuracy: 0.8883\n",
      "Epoch 336/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3132 - accuracy: 0.9089 - val_loss: 0.3916 - val_accuracy: 0.8873\n",
      "Epoch 337/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3252 - accuracy: 0.9033 - val_loss: 0.3877 - val_accuracy: 0.8839\n",
      "Epoch 338/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3122 - accuracy: 0.9086 - val_loss: 0.3603 - val_accuracy: 0.8946\n",
      "Epoch 339/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3205 - accuracy: 0.9038 - val_loss: 0.3895 - val_accuracy: 0.8873\n",
      "Epoch 340/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.3130 - accuracy: 0.9084 - val_loss: 0.3787 - val_accuracy: 0.8893\n",
      "Epoch 341/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3215 - accuracy: 0.9064 - val_loss: 0.3671 - val_accuracy: 0.8936\n",
      "Epoch 342/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3118 - accuracy: 0.9039 - val_loss: 0.3631 - val_accuracy: 0.8888\n",
      "Epoch 343/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3208 - accuracy: 0.9042 - val_loss: 0.4057 - val_accuracy: 0.8786\n",
      "Epoch 344/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3166 - accuracy: 0.9088 - val_loss: 0.3787 - val_accuracy: 0.8898\n",
      "Epoch 345/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3235 - accuracy: 0.9016 - val_loss: 0.4109 - val_accuracy: 0.8796\n",
      "Epoch 346/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3154 - accuracy: 0.9060 - val_loss: 0.3777 - val_accuracy: 0.8941\n",
      "Epoch 347/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3132 - accuracy: 0.9104 - val_loss: 0.3842 - val_accuracy: 0.8864\n",
      "Epoch 348/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3018 - accuracy: 0.9103 - val_loss: 0.3839 - val_accuracy: 0.8834\n",
      "Epoch 349/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3292 - accuracy: 0.9055 - val_loss: 0.3665 - val_accuracy: 0.8888\n",
      "Epoch 350/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2970 - accuracy: 0.9112 - val_loss: 0.3635 - val_accuracy: 0.8907\n",
      "Epoch 351/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3358 - accuracy: 0.8985 - val_loss: 0.3652 - val_accuracy: 0.8961\n",
      "Epoch 352/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3096 - accuracy: 0.9100 - val_loss: 0.3702 - val_accuracy: 0.8951\n",
      "Epoch 353/1000\n",
      "257/257 [==============================] - 22s 85ms/step - loss: 0.2973 - accuracy: 0.9086 - val_loss: 0.3797 - val_accuracy: 0.8868\n",
      "Epoch 354/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3112 - accuracy: 0.9072 - val_loss: 0.3892 - val_accuracy: 0.8893\n",
      "Epoch 355/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3036 - accuracy: 0.9092 - val_loss: 0.3910 - val_accuracy: 0.8868\n",
      "Epoch 356/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3210 - accuracy: 0.9044 - val_loss: 0.3603 - val_accuracy: 0.8898\n",
      "Epoch 357/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3144 - accuracy: 0.9033 - val_loss: 0.3860 - val_accuracy: 0.8868\n",
      "Epoch 358/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2968 - accuracy: 0.9122 - val_loss: 0.3751 - val_accuracy: 0.8864\n",
      "Epoch 359/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3034 - accuracy: 0.9073 - val_loss: 0.3576 - val_accuracy: 0.8970\n",
      "Epoch 360/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3149 - accuracy: 0.9049 - val_loss: 0.3764 - val_accuracy: 0.8839\n",
      "Epoch 361/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3010 - accuracy: 0.9121 - val_loss: 0.4286 - val_accuracy: 0.8674\n",
      "Epoch 362/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3061 - accuracy: 0.9105 - val_loss: 0.3899 - val_accuracy: 0.8849\n",
      "Epoch 363/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3077 - accuracy: 0.9082 - val_loss: 0.3727 - val_accuracy: 0.8893\n",
      "Epoch 364/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3069 - accuracy: 0.9072 - val_loss: 0.3718 - val_accuracy: 0.8898\n",
      "Epoch 365/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2881 - accuracy: 0.9143 - val_loss: 0.3552 - val_accuracy: 0.8951\n",
      "Epoch 366/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3203 - accuracy: 0.9050 - val_loss: 0.3634 - val_accuracy: 0.8893\n",
      "Epoch 367/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2968 - accuracy: 0.9139 - val_loss: 0.3628 - val_accuracy: 0.8912\n",
      "Epoch 368/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3101 - accuracy: 0.9072 - val_loss: 0.3707 - val_accuracy: 0.8922\n",
      "Epoch 369/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3062 - accuracy: 0.9072 - val_loss: 0.3961 - val_accuracy: 0.8825\n",
      "Epoch 370/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3029 - accuracy: 0.9084 - val_loss: 0.3692 - val_accuracy: 0.8898\n",
      "Epoch 371/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3063 - accuracy: 0.9095 - val_loss: 0.4103 - val_accuracy: 0.8796\n",
      "Epoch 372/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2999 - accuracy: 0.9087 - val_loss: 0.3734 - val_accuracy: 0.8864\n",
      "Epoch 373/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2971 - accuracy: 0.9094 - val_loss: 0.3518 - val_accuracy: 0.8975\n",
      "Epoch 374/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3044 - accuracy: 0.9115 - val_loss: 0.3793 - val_accuracy: 0.8864\n",
      "Epoch 375/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2968 - accuracy: 0.9116 - val_loss: 0.3570 - val_accuracy: 0.8932\n",
      "Epoch 376/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3001 - accuracy: 0.9127 - val_loss: 0.3547 - val_accuracy: 0.8956\n",
      "Epoch 377/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2974 - accuracy: 0.9149 - val_loss: 0.3607 - val_accuracy: 0.8907\n",
      "Epoch 378/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2889 - accuracy: 0.9173 - val_loss: 0.3586 - val_accuracy: 0.8893\n",
      "Epoch 379/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3048 - accuracy: 0.9059 - val_loss: 0.3785 - val_accuracy: 0.8912\n",
      "Epoch 380/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3042 - accuracy: 0.9101 - val_loss: 0.3565 - val_accuracy: 0.8951\n",
      "Epoch 381/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2999 - accuracy: 0.9120 - val_loss: 0.3443 - val_accuracy: 0.8975\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2946 - accuracy: 0.9128 - val_loss: 0.3797 - val_accuracy: 0.8844\n",
      "Epoch 383/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2978 - accuracy: 0.9097 - val_loss: 0.3434 - val_accuracy: 0.8995\n",
      "Epoch 384/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2947 - accuracy: 0.9089 - val_loss: 0.3830 - val_accuracy: 0.8907\n",
      "Epoch 385/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2956 - accuracy: 0.9125 - val_loss: 0.3537 - val_accuracy: 0.8907\n",
      "Epoch 386/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2911 - accuracy: 0.9139 - val_loss: 0.3600 - val_accuracy: 0.8936\n",
      "Epoch 387/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2951 - accuracy: 0.9136 - val_loss: 0.3657 - val_accuracy: 0.8932\n",
      "Epoch 388/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2914 - accuracy: 0.9123 - val_loss: 0.3540 - val_accuracy: 0.8961\n",
      "Epoch 389/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2973 - accuracy: 0.9077 - val_loss: 0.3476 - val_accuracy: 0.9000\n",
      "Epoch 390/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3076 - accuracy: 0.9117 - val_loss: 0.3616 - val_accuracy: 0.8898\n",
      "Epoch 391/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2822 - accuracy: 0.9121 - val_loss: 0.4075 - val_accuracy: 0.8791\n",
      "Epoch 392/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3014 - accuracy: 0.9098 - val_loss: 0.3547 - val_accuracy: 0.8917\n",
      "Epoch 393/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2874 - accuracy: 0.9167 - val_loss: 0.3539 - val_accuracy: 0.8941\n",
      "Epoch 394/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.3026 - accuracy: 0.9079 - val_loss: 0.3526 - val_accuracy: 0.8932\n",
      "Epoch 395/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2947 - accuracy: 0.9106 - val_loss: 0.3553 - val_accuracy: 0.8966\n",
      "Epoch 396/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2862 - accuracy: 0.9150 - val_loss: 0.3431 - val_accuracy: 0.8975\n",
      "Epoch 397/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2847 - accuracy: 0.9155 - val_loss: 0.3365 - val_accuracy: 0.9009\n",
      "Epoch 398/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2935 - accuracy: 0.9120 - val_loss: 0.3424 - val_accuracy: 0.8995\n",
      "Epoch 399/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2913 - accuracy: 0.9115 - val_loss: 0.3474 - val_accuracy: 0.8966\n",
      "Epoch 400/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2961 - accuracy: 0.9147 - val_loss: 0.3628 - val_accuracy: 0.8902\n",
      "Epoch 401/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2861 - accuracy: 0.9167 - val_loss: 0.3578 - val_accuracy: 0.8917\n",
      "Epoch 402/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2878 - accuracy: 0.9111 - val_loss: 0.3697 - val_accuracy: 0.8922\n",
      "Epoch 403/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2867 - accuracy: 0.9144 - val_loss: 0.3552 - val_accuracy: 0.8956\n",
      "Epoch 404/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2865 - accuracy: 0.9158 - val_loss: 0.4051 - val_accuracy: 0.8796\n",
      "Epoch 405/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2868 - accuracy: 0.9135 - val_loss: 0.3813 - val_accuracy: 0.8805\n",
      "Epoch 406/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2881 - accuracy: 0.9141 - val_loss: 0.3584 - val_accuracy: 0.8907\n",
      "Epoch 407/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2873 - accuracy: 0.9166 - val_loss: 0.3630 - val_accuracy: 0.8946\n",
      "Epoch 408/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2911 - accuracy: 0.9104 - val_loss: 0.3926 - val_accuracy: 0.8834\n",
      "Epoch 409/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2830 - accuracy: 0.9199 - val_loss: 0.3419 - val_accuracy: 0.9019\n",
      "Epoch 410/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2909 - accuracy: 0.9103 - val_loss: 0.3605 - val_accuracy: 0.8975\n",
      "Epoch 411/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2898 - accuracy: 0.9117 - val_loss: 0.3566 - val_accuracy: 0.8922\n",
      "Epoch 412/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2880 - accuracy: 0.9158 - val_loss: 0.3615 - val_accuracy: 0.8985\n",
      "Epoch 413/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2896 - accuracy: 0.9131 - val_loss: 0.3488 - val_accuracy: 0.8961\n",
      "Epoch 414/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2800 - accuracy: 0.9178 - val_loss: 0.3410 - val_accuracy: 0.8985\n",
      "Epoch 415/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2769 - accuracy: 0.9200 - val_loss: 0.3627 - val_accuracy: 0.8902\n",
      "Epoch 416/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2964 - accuracy: 0.9151 - val_loss: 0.3584 - val_accuracy: 0.8917\n",
      "Epoch 417/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2835 - accuracy: 0.9164 - val_loss: 0.3408 - val_accuracy: 0.8990\n",
      "Epoch 418/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2970 - accuracy: 0.9109 - val_loss: 0.3730 - val_accuracy: 0.8932\n",
      "Epoch 419/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2827 - accuracy: 0.9153 - val_loss: 0.3428 - val_accuracy: 0.8995\n",
      "Epoch 420/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2874 - accuracy: 0.9146 - val_loss: 0.3709 - val_accuracy: 0.8912\n",
      "Epoch 421/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2761 - accuracy: 0.9171 - val_loss: 0.3786 - val_accuracy: 0.8917\n",
      "Epoch 422/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2823 - accuracy: 0.9159 - val_loss: 0.3534 - val_accuracy: 0.8946\n",
      "Epoch 423/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2826 - accuracy: 0.9176 - val_loss: 0.3649 - val_accuracy: 0.8878\n",
      "Epoch 424/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2911 - accuracy: 0.9164 - val_loss: 0.3575 - val_accuracy: 0.8970\n",
      "Epoch 425/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2797 - accuracy: 0.9155 - val_loss: 0.3414 - val_accuracy: 0.9009\n",
      "Epoch 426/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2777 - accuracy: 0.9201 - val_loss: 0.3545 - val_accuracy: 0.8985\n",
      "Epoch 427/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2848 - accuracy: 0.9119 - val_loss: 0.3601 - val_accuracy: 0.8932\n",
      "Epoch 428/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2861 - accuracy: 0.9147 - val_loss: 0.3707 - val_accuracy: 0.8941\n",
      "Epoch 429/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2880 - accuracy: 0.9105 - val_loss: 0.3451 - val_accuracy: 0.8951\n",
      "Epoch 430/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2674 - accuracy: 0.9181 - val_loss: 0.3380 - val_accuracy: 0.9019\n",
      "Epoch 431/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2872 - accuracy: 0.9131 - val_loss: 0.4130 - val_accuracy: 0.8776\n",
      "Epoch 432/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2901 - accuracy: 0.9098 - val_loss: 0.3696 - val_accuracy: 0.8941\n",
      "Epoch 433/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2733 - accuracy: 0.9189 - val_loss: 0.3472 - val_accuracy: 0.8951\n",
      "Epoch 434/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2840 - accuracy: 0.9154 - val_loss: 0.3621 - val_accuracy: 0.8907\n",
      "Epoch 435/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2816 - accuracy: 0.9128 - val_loss: 0.3409 - val_accuracy: 0.9004\n",
      "Epoch 436/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2778 - accuracy: 0.9165 - val_loss: 0.3331 - val_accuracy: 0.9024\n",
      "Epoch 437/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2810 - accuracy: 0.9150 - val_loss: 0.3408 - val_accuracy: 0.8966\n",
      "Epoch 438/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2684 - accuracy: 0.9221 - val_loss: 0.3445 - val_accuracy: 0.8951\n",
      "Epoch 439/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2786 - accuracy: 0.9147 - val_loss: 0.3370 - val_accuracy: 0.9024\n",
      "Epoch 440/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2796 - accuracy: 0.9172 - val_loss: 0.3391 - val_accuracy: 0.8995\n",
      "Epoch 441/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2742 - accuracy: 0.9174 - val_loss: 0.3352 - val_accuracy: 0.9004\n",
      "Epoch 442/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2697 - accuracy: 0.9193 - val_loss: 0.3669 - val_accuracy: 0.8946\n",
      "Epoch 443/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2741 - accuracy: 0.9205 - val_loss: 0.3562 - val_accuracy: 0.8970\n",
      "Epoch 444/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2664 - accuracy: 0.9218 - val_loss: 0.3904 - val_accuracy: 0.8805\n",
      "Epoch 445/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2733 - accuracy: 0.9203 - val_loss: 0.3440 - val_accuracy: 0.8956\n",
      "Epoch 446/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2849 - accuracy: 0.9159 - val_loss: 0.3478 - val_accuracy: 0.8961\n",
      "Epoch 447/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2738 - accuracy: 0.9186 - val_loss: 0.3490 - val_accuracy: 0.8980\n",
      "Epoch 448/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2774 - accuracy: 0.9167 - val_loss: 0.3465 - val_accuracy: 0.8951\n",
      "Epoch 449/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2624 - accuracy: 0.9232 - val_loss: 0.3505 - val_accuracy: 0.8936\n",
      "Epoch 450/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2713 - accuracy: 0.9142 - val_loss: 0.3591 - val_accuracy: 0.8917\n",
      "Epoch 451/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2757 - accuracy: 0.9177 - val_loss: 0.3727 - val_accuracy: 0.8859\n",
      "Epoch 452/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2692 - accuracy: 0.9201 - val_loss: 0.3445 - val_accuracy: 0.8951\n",
      "Epoch 453/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2762 - accuracy: 0.9160 - val_loss: 0.3667 - val_accuracy: 0.8893\n",
      "Epoch 454/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2727 - accuracy: 0.9192 - val_loss: 0.3354 - val_accuracy: 0.8995\n",
      "Epoch 455/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2688 - accuracy: 0.9208 - val_loss: 0.3752 - val_accuracy: 0.8873\n",
      "Epoch 456/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2680 - accuracy: 0.9187 - val_loss: 0.3303 - val_accuracy: 0.9009\n",
      "Epoch 457/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2709 - accuracy: 0.9186 - val_loss: 0.3539 - val_accuracy: 0.8990\n",
      "Epoch 458/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2718 - accuracy: 0.9200 - val_loss: 0.3635 - val_accuracy: 0.8966\n",
      "Epoch 459/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2764 - accuracy: 0.9159 - val_loss: 0.3524 - val_accuracy: 0.8961\n",
      "Epoch 460/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2702 - accuracy: 0.9221 - val_loss: 0.3382 - val_accuracy: 0.9019\n",
      "Epoch 461/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2686 - accuracy: 0.9198 - val_loss: 0.3350 - val_accuracy: 0.9034\n",
      "Epoch 462/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2667 - accuracy: 0.9192 - val_loss: 0.3469 - val_accuracy: 0.8956\n",
      "Epoch 463/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2686 - accuracy: 0.9225 - val_loss: 0.3564 - val_accuracy: 0.8995\n",
      "Epoch 464/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2719 - accuracy: 0.9206 - val_loss: 0.3403 - val_accuracy: 0.9014\n",
      "Epoch 465/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2716 - accuracy: 0.9205 - val_loss: 0.3596 - val_accuracy: 0.8975\n",
      "Epoch 466/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2677 - accuracy: 0.9211 - val_loss: 0.3688 - val_accuracy: 0.8946\n",
      "Epoch 467/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2670 - accuracy: 0.9183 - val_loss: 0.3316 - val_accuracy: 0.9043\n",
      "Epoch 468/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2764 - accuracy: 0.9172 - val_loss: 0.3326 - val_accuracy: 0.9029\n",
      "Epoch 469/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2624 - accuracy: 0.9210 - val_loss: 0.3331 - val_accuracy: 0.9019\n",
      "Epoch 470/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2666 - accuracy: 0.9208 - val_loss: 0.3383 - val_accuracy: 0.9014\n",
      "Epoch 471/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2673 - accuracy: 0.9199 - val_loss: 0.3205 - val_accuracy: 0.9053\n",
      "Epoch 472/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2727 - accuracy: 0.9161 - val_loss: 0.3387 - val_accuracy: 0.9034\n",
      "Epoch 473/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2669 - accuracy: 0.9225 - val_loss: 0.3304 - val_accuracy: 0.9019\n",
      "Epoch 474/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2641 - accuracy: 0.9216 - val_loss: 0.3520 - val_accuracy: 0.8970\n",
      "Epoch 475/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2665 - accuracy: 0.9225 - val_loss: 0.3295 - val_accuracy: 0.9043\n",
      "Epoch 476/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2613 - accuracy: 0.9199 - val_loss: 0.3333 - val_accuracy: 0.9009\n",
      "Epoch 477/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2691 - accuracy: 0.9205 - val_loss: 0.3287 - val_accuracy: 0.9024\n",
      "Epoch 478/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2564 - accuracy: 0.9232 - val_loss: 0.3312 - val_accuracy: 0.8975\n",
      "Epoch 479/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2651 - accuracy: 0.9193 - val_loss: 0.3302 - val_accuracy: 0.9034\n",
      "Epoch 480/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2684 - accuracy: 0.9201 - val_loss: 0.3553 - val_accuracy: 0.8941\n",
      "Epoch 481/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2627 - accuracy: 0.9212 - val_loss: 0.3637 - val_accuracy: 0.8936\n",
      "Epoch 482/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2643 - accuracy: 0.9215 - val_loss: 0.3390 - val_accuracy: 0.8980\n",
      "Epoch 483/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2652 - accuracy: 0.9211 - val_loss: 0.3391 - val_accuracy: 0.9004\n",
      "Epoch 484/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2558 - accuracy: 0.9244 - val_loss: 0.3332 - val_accuracy: 0.9004\n",
      "Epoch 485/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2569 - accuracy: 0.9205 - val_loss: 0.3321 - val_accuracy: 0.9034\n",
      "Epoch 486/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2621 - accuracy: 0.9204 - val_loss: 0.3285 - val_accuracy: 0.9034\n",
      "Epoch 487/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2676 - accuracy: 0.9199 - val_loss: 0.3377 - val_accuracy: 0.8961\n",
      "Epoch 488/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2569 - accuracy: 0.9217 - val_loss: 0.3472 - val_accuracy: 0.8951\n",
      "Epoch 489/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2632 - accuracy: 0.9206 - val_loss: 0.3270 - val_accuracy: 0.9024\n",
      "Epoch 490/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2614 - accuracy: 0.9214 - val_loss: 0.3357 - val_accuracy: 0.9019\n",
      "Epoch 491/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2654 - accuracy: 0.9192 - val_loss: 0.3367 - val_accuracy: 0.9029\n",
      "Epoch 492/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2595 - accuracy: 0.9228 - val_loss: 0.3324 - val_accuracy: 0.9019\n",
      "Epoch 493/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2664 - accuracy: 0.9190 - val_loss: 0.3195 - val_accuracy: 0.9048\n",
      "Epoch 494/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2578 - accuracy: 0.9218 - val_loss: 0.3452 - val_accuracy: 0.8975\n",
      "Epoch 495/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2593 - accuracy: 0.9243 - val_loss: 0.3371 - val_accuracy: 0.9000\n",
      "Epoch 496/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2594 - accuracy: 0.9229 - val_loss: 0.3383 - val_accuracy: 0.8985\n",
      "Epoch 497/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2604 - accuracy: 0.9249 - val_loss: 0.3281 - val_accuracy: 0.9038\n",
      "Epoch 498/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2626 - accuracy: 0.9220 - val_loss: 0.3253 - val_accuracy: 0.9072\n",
      "Epoch 499/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2553 - accuracy: 0.9237 - val_loss: 0.3309 - val_accuracy: 0.9048\n",
      "Epoch 500/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2609 - accuracy: 0.9206 - val_loss: 0.3295 - val_accuracy: 0.8985\n",
      "Epoch 501/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2515 - accuracy: 0.9236 - val_loss: 0.3182 - val_accuracy: 0.9087\n",
      "Epoch 502/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2570 - accuracy: 0.9223 - val_loss: 0.3285 - val_accuracy: 0.9004\n",
      "Epoch 503/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2625 - accuracy: 0.9222 - val_loss: 0.3165 - val_accuracy: 0.9068\n",
      "Epoch 504/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2555 - accuracy: 0.9221 - val_loss: 0.3431 - val_accuracy: 0.8985\n",
      "Epoch 505/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2548 - accuracy: 0.9259 - val_loss: 0.3389 - val_accuracy: 0.8990\n",
      "Epoch 506/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2604 - accuracy: 0.9225 - val_loss: 0.3713 - val_accuracy: 0.8927\n",
      "Epoch 507/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2556 - accuracy: 0.9254 - val_loss: 0.3484 - val_accuracy: 0.8922\n",
      "Epoch 508/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2610 - accuracy: 0.9251 - val_loss: 0.3244 - val_accuracy: 0.9043\n",
      "Epoch 509/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2572 - accuracy: 0.9243 - val_loss: 0.3187 - val_accuracy: 0.9072\n",
      "Epoch 510/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2509 - accuracy: 0.9250 - val_loss: 0.3357 - val_accuracy: 0.9029\n",
      "Epoch 511/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2558 - accuracy: 0.9259 - val_loss: 0.3531 - val_accuracy: 0.8951\n",
      "Epoch 512/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2546 - accuracy: 0.9229 - val_loss: 0.3333 - val_accuracy: 0.9029\n",
      "Epoch 513/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2568 - accuracy: 0.9229 - val_loss: 0.3219 - val_accuracy: 0.9048\n",
      "Epoch 514/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2556 - accuracy: 0.9247 - val_loss: 0.3180 - val_accuracy: 0.9077\n",
      "Epoch 515/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2587 - accuracy: 0.9237 - val_loss: 0.3444 - val_accuracy: 0.8985\n",
      "Epoch 516/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2528 - accuracy: 0.9249 - val_loss: 0.3273 - val_accuracy: 0.9043\n",
      "Epoch 517/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2518 - accuracy: 0.9247 - val_loss: 0.3458 - val_accuracy: 0.9024\n",
      "Epoch 518/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2490 - accuracy: 0.9242 - val_loss: 0.3754 - val_accuracy: 0.8922\n",
      "Epoch 519/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2546 - accuracy: 0.9233 - val_loss: 0.3232 - val_accuracy: 0.9053\n",
      "Epoch 520/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2602 - accuracy: 0.9222 - val_loss: 0.3161 - val_accuracy: 0.9111\n",
      "Epoch 521/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2562 - accuracy: 0.9243 - val_loss: 0.3553 - val_accuracy: 0.8966\n",
      "Epoch 522/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2582 - accuracy: 0.9233 - val_loss: 0.3299 - val_accuracy: 0.8980\n",
      "Epoch 523/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2519 - accuracy: 0.9273 - val_loss: 0.3279 - val_accuracy: 0.9043\n",
      "Epoch 524/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2519 - accuracy: 0.9227 - val_loss: 0.3417 - val_accuracy: 0.8970\n",
      "Epoch 525/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2495 - accuracy: 0.9279 - val_loss: 0.3496 - val_accuracy: 0.8941\n",
      "Epoch 526/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2498 - accuracy: 0.9245 - val_loss: 0.3361 - val_accuracy: 0.9000\n",
      "Epoch 527/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2502 - accuracy: 0.9279 - val_loss: 0.3387 - val_accuracy: 0.8966\n",
      "Epoch 528/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2490 - accuracy: 0.9267 - val_loss: 0.3728 - val_accuracy: 0.8888\n",
      "Epoch 529/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2521 - accuracy: 0.9240 - val_loss: 0.3242 - val_accuracy: 0.9034\n",
      "Epoch 530/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2562 - accuracy: 0.9212 - val_loss: 0.3293 - val_accuracy: 0.8990\n",
      "Epoch 531/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2502 - accuracy: 0.9242 - val_loss: 0.3176 - val_accuracy: 0.9121\n",
      "Epoch 532/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2487 - accuracy: 0.9232 - val_loss: 0.3315 - val_accuracy: 0.9043\n",
      "Epoch 533/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2528 - accuracy: 0.9226 - val_loss: 0.3403 - val_accuracy: 0.8990\n",
      "Epoch 534/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2449 - accuracy: 0.9262 - val_loss: 0.3108 - val_accuracy: 0.9092\n",
      "Epoch 535/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2486 - accuracy: 0.9281 - val_loss: 0.3248 - val_accuracy: 0.9038\n",
      "Epoch 536/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2567 - accuracy: 0.9226 - val_loss: 0.3560 - val_accuracy: 0.8970\n",
      "Epoch 537/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2458 - accuracy: 0.9268 - val_loss: 0.3437 - val_accuracy: 0.8946\n",
      "Epoch 538/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2565 - accuracy: 0.9243 - val_loss: 0.3473 - val_accuracy: 0.8970\n",
      "Epoch 539/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2422 - accuracy: 0.9281 - val_loss: 0.3406 - val_accuracy: 0.8985\n",
      "Epoch 540/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2650 - accuracy: 0.9217 - val_loss: 0.3477 - val_accuracy: 0.8956\n",
      "Epoch 541/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2442 - accuracy: 0.9280 - val_loss: 0.3209 - val_accuracy: 0.9053\n",
      "Epoch 542/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2398 - accuracy: 0.9278 - val_loss: 0.3342 - val_accuracy: 0.9038\n",
      "Epoch 543/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2469 - accuracy: 0.9253 - val_loss: 0.3267 - val_accuracy: 0.9019\n",
      "Epoch 544/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2473 - accuracy: 0.9237 - val_loss: 0.3088 - val_accuracy: 0.9106\n",
      "Epoch 545/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2611 - accuracy: 0.9189 - val_loss: 0.3415 - val_accuracy: 0.8980\n",
      "Epoch 546/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2539 - accuracy: 0.9233 - val_loss: 0.3326 - val_accuracy: 0.9019\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2417 - accuracy: 0.9278 - val_loss: 0.3111 - val_accuracy: 0.9068\n",
      "Epoch 548/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2443 - accuracy: 0.9281 - val_loss: 0.3180 - val_accuracy: 0.9072\n",
      "Epoch 549/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2519 - accuracy: 0.9225 - val_loss: 0.3109 - val_accuracy: 0.9102\n",
      "Epoch 550/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2453 - accuracy: 0.9278 - val_loss: 0.3321 - val_accuracy: 0.9019\n",
      "Epoch 551/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2451 - accuracy: 0.9281 - val_loss: 0.3377 - val_accuracy: 0.9000\n",
      "Epoch 552/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2424 - accuracy: 0.9278 - val_loss: 0.3218 - val_accuracy: 0.9068\n",
      "Epoch 553/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2422 - accuracy: 0.9286 - val_loss: 0.3365 - val_accuracy: 0.8975\n",
      "Epoch 554/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2495 - accuracy: 0.9257 - val_loss: 0.3221 - val_accuracy: 0.9053\n",
      "Epoch 555/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2471 - accuracy: 0.9237 - val_loss: 0.3407 - val_accuracy: 0.8956\n",
      "Epoch 556/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2380 - accuracy: 0.9284 - val_loss: 0.4022 - val_accuracy: 0.8844\n",
      "Epoch 557/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2511 - accuracy: 0.9234 - val_loss: 0.3164 - val_accuracy: 0.9077\n",
      "Epoch 558/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2490 - accuracy: 0.9253 - val_loss: 0.3199 - val_accuracy: 0.9034\n",
      "Epoch 559/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2441 - accuracy: 0.9272 - val_loss: 0.3320 - val_accuracy: 0.9019\n",
      "Epoch 560/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2481 - accuracy: 0.9243 - val_loss: 0.3255 - val_accuracy: 0.9058\n",
      "Epoch 561/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2476 - accuracy: 0.9262 - val_loss: 0.3273 - val_accuracy: 0.9038\n",
      "Epoch 562/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2358 - accuracy: 0.9275 - val_loss: 0.3181 - val_accuracy: 0.9087\n",
      "Epoch 563/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2519 - accuracy: 0.9250 - val_loss: 0.3193 - val_accuracy: 0.9043\n",
      "Epoch 564/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2447 - accuracy: 0.9240 - val_loss: 0.3372 - val_accuracy: 0.9029\n",
      "Epoch 565/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2434 - accuracy: 0.9273 - val_loss: 0.3247 - val_accuracy: 0.9038\n",
      "Epoch 566/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2390 - accuracy: 0.9286 - val_loss: 0.3537 - val_accuracy: 0.8936\n",
      "Epoch 567/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2400 - accuracy: 0.9277 - val_loss: 0.3104 - val_accuracy: 0.9087\n",
      "Epoch 568/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2457 - accuracy: 0.9276 - val_loss: 0.3293 - val_accuracy: 0.9048\n",
      "Epoch 569/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2444 - accuracy: 0.9276 - val_loss: 0.3263 - val_accuracy: 0.9048\n",
      "Epoch 570/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2378 - accuracy: 0.9284 - val_loss: 0.3583 - val_accuracy: 0.8946\n",
      "Epoch 571/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2446 - accuracy: 0.9284 - val_loss: 0.3133 - val_accuracy: 0.9058\n",
      "Epoch 572/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2435 - accuracy: 0.9278 - val_loss: 0.3204 - val_accuracy: 0.9048\n",
      "Epoch 573/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2425 - accuracy: 0.9277 - val_loss: 0.3144 - val_accuracy: 0.9063\n",
      "Epoch 574/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2446 - accuracy: 0.9262 - val_loss: 0.3424 - val_accuracy: 0.8975\n",
      "Epoch 575/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2493 - accuracy: 0.9249 - val_loss: 0.3555 - val_accuracy: 0.8995\n",
      "Epoch 576/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2383 - accuracy: 0.9287 - val_loss: 0.3184 - val_accuracy: 0.9072\n",
      "Epoch 577/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2357 - accuracy: 0.9275 - val_loss: 0.3498 - val_accuracy: 0.9009\n",
      "Epoch 578/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2361 - accuracy: 0.9280 - val_loss: 0.3162 - val_accuracy: 0.9072\n",
      "Epoch 579/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2408 - accuracy: 0.9278 - val_loss: 0.3477 - val_accuracy: 0.8966\n",
      "Epoch 580/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2379 - accuracy: 0.9278 - val_loss: 0.3239 - val_accuracy: 0.9029\n",
      "Epoch 581/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2471 - accuracy: 0.9275 - val_loss: 0.3159 - val_accuracy: 0.9024\n",
      "Epoch 582/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2362 - accuracy: 0.9281 - val_loss: 0.3202 - val_accuracy: 0.9058\n",
      "Epoch 583/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2489 - accuracy: 0.9249 - val_loss: 0.3002 - val_accuracy: 0.9102\n",
      "Epoch 584/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2288 - accuracy: 0.9294 - val_loss: 0.3360 - val_accuracy: 0.8956\n",
      "Epoch 585/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2486 - accuracy: 0.9276 - val_loss: 0.3538 - val_accuracy: 0.8936\n",
      "Epoch 586/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2375 - accuracy: 0.9297 - val_loss: 0.3157 - val_accuracy: 0.9087\n",
      "Epoch 587/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2395 - accuracy: 0.9300 - val_loss: 0.3176 - val_accuracy: 0.9097\n",
      "Epoch 588/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2313 - accuracy: 0.9276 - val_loss: 0.3070 - val_accuracy: 0.9077\n",
      "Epoch 589/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2364 - accuracy: 0.9281 - val_loss: 0.3542 - val_accuracy: 0.8980\n",
      "Epoch 590/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2395 - accuracy: 0.9289 - val_loss: 0.3235 - val_accuracy: 0.9053\n",
      "Epoch 591/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2320 - accuracy: 0.9314 - val_loss: 0.3188 - val_accuracy: 0.9058\n",
      "Epoch 592/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2416 - accuracy: 0.9272 - val_loss: 0.3426 - val_accuracy: 0.9004\n",
      "Epoch 593/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2347 - accuracy: 0.9287 - val_loss: 0.3234 - val_accuracy: 0.9063\n",
      "Epoch 594/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2305 - accuracy: 0.9275 - val_loss: 0.3128 - val_accuracy: 0.9068\n",
      "Epoch 595/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2366 - accuracy: 0.9264 - val_loss: 0.3264 - val_accuracy: 0.9029\n",
      "Epoch 596/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2416 - accuracy: 0.9290 - val_loss: 0.3123 - val_accuracy: 0.9087\n",
      "Epoch 597/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2458 - accuracy: 0.9298 - val_loss: 0.3126 - val_accuracy: 0.9068\n",
      "Epoch 598/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2402 - accuracy: 0.9292 - val_loss: 0.3213 - val_accuracy: 0.9058\n",
      "Epoch 599/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2312 - accuracy: 0.9318 - val_loss: 0.3331 - val_accuracy: 0.9000\n",
      "Epoch 600/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2354 - accuracy: 0.9262 - val_loss: 0.3276 - val_accuracy: 0.9053\n",
      "Epoch 601/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2375 - accuracy: 0.9288 - val_loss: 0.3267 - val_accuracy: 0.8985\n",
      "Epoch 602/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2445 - accuracy: 0.9242 - val_loss: 0.3161 - val_accuracy: 0.9063\n",
      "Epoch 603/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2284 - accuracy: 0.9320 - val_loss: 0.3664 - val_accuracy: 0.8907\n",
      "Epoch 604/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2299 - accuracy: 0.9318 - val_loss: 0.3129 - val_accuracy: 0.9077\n",
      "Epoch 605/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2329 - accuracy: 0.9282 - val_loss: 0.3069 - val_accuracy: 0.9116\n",
      "Epoch 606/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2386 - accuracy: 0.9302 - val_loss: 0.3243 - val_accuracy: 0.9063\n",
      "Epoch 607/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2321 - accuracy: 0.9301 - val_loss: 0.3403 - val_accuracy: 0.8985\n",
      "Epoch 608/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2363 - accuracy: 0.9277 - val_loss: 0.3065 - val_accuracy: 0.9072\n",
      "Epoch 609/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2336 - accuracy: 0.9298 - val_loss: 0.3028 - val_accuracy: 0.9077\n",
      "Epoch 610/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2339 - accuracy: 0.9273 - val_loss: 0.3425 - val_accuracy: 0.8970\n",
      "Epoch 611/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2357 - accuracy: 0.9268 - val_loss: 0.3312 - val_accuracy: 0.9029\n",
      "Epoch 612/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2399 - accuracy: 0.9298 - val_loss: 0.3415 - val_accuracy: 0.9000\n",
      "Epoch 613/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2342 - accuracy: 0.9296 - val_loss: 0.3080 - val_accuracy: 0.9077\n",
      "Epoch 614/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2265 - accuracy: 0.9322 - val_loss: 0.3252 - val_accuracy: 0.9029\n",
      "Epoch 615/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2377 - accuracy: 0.9319 - val_loss: 0.3209 - val_accuracy: 0.9048\n",
      "Epoch 616/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2320 - accuracy: 0.9305 - val_loss: 0.3245 - val_accuracy: 0.9038\n",
      "Epoch 617/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2317 - accuracy: 0.9300 - val_loss: 0.3213 - val_accuracy: 0.9043\n",
      "Epoch 618/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2394 - accuracy: 0.9295 - val_loss: 0.3057 - val_accuracy: 0.9072\n",
      "Epoch 619/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2284 - accuracy: 0.9318 - val_loss: 0.3022 - val_accuracy: 0.9087\n",
      "Epoch 620/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2351 - accuracy: 0.9301 - val_loss: 0.3231 - val_accuracy: 0.9014\n",
      "Epoch 621/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2327 - accuracy: 0.9295 - val_loss: 0.2984 - val_accuracy: 0.9087\n",
      "Epoch 622/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2340 - accuracy: 0.9300 - val_loss: 0.3004 - val_accuracy: 0.9082\n",
      "Epoch 623/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2250 - accuracy: 0.9318 - val_loss: 0.3107 - val_accuracy: 0.9043\n",
      "Epoch 624/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2211 - accuracy: 0.9322 - val_loss: 0.3098 - val_accuracy: 0.9063\n",
      "Epoch 625/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2418 - accuracy: 0.9244 - val_loss: 0.3044 - val_accuracy: 0.9087\n",
      "Epoch 626/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2308 - accuracy: 0.9323 - val_loss: 0.2974 - val_accuracy: 0.9102\n",
      "Epoch 627/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2362 - accuracy: 0.9280 - val_loss: 0.3216 - val_accuracy: 0.9053\n",
      "Epoch 628/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2238 - accuracy: 0.9337 - val_loss: 0.2992 - val_accuracy: 0.9106\n",
      "Epoch 629/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2367 - accuracy: 0.9273 - val_loss: 0.3126 - val_accuracy: 0.9063\n",
      "Epoch 630/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2230 - accuracy: 0.9325 - val_loss: 0.3086 - val_accuracy: 0.9048\n",
      "Epoch 631/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2325 - accuracy: 0.9297 - val_loss: 0.3033 - val_accuracy: 0.9077\n",
      "Epoch 632/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2264 - accuracy: 0.9321 - val_loss: 0.3090 - val_accuracy: 0.9077\n",
      "Epoch 633/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2246 - accuracy: 0.9313 - val_loss: 0.3104 - val_accuracy: 0.9077\n",
      "Epoch 634/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2305 - accuracy: 0.9300 - val_loss: 0.3125 - val_accuracy: 0.9063\n",
      "Epoch 635/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2333 - accuracy: 0.9295 - val_loss: 0.3122 - val_accuracy: 0.9072\n",
      "Epoch 636/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2329 - accuracy: 0.9297 - val_loss: 0.3060 - val_accuracy: 0.9102\n",
      "Epoch 637/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2251 - accuracy: 0.9315 - val_loss: 0.3158 - val_accuracy: 0.9077\n",
      "Epoch 638/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2335 - accuracy: 0.9317 - val_loss: 0.2934 - val_accuracy: 0.9102\n",
      "Epoch 639/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2337 - accuracy: 0.9314 - val_loss: 0.3200 - val_accuracy: 0.9053\n",
      "Epoch 640/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2282 - accuracy: 0.9304 - val_loss: 0.2999 - val_accuracy: 0.9126\n",
      "Epoch 641/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2191 - accuracy: 0.9342 - val_loss: 0.3188 - val_accuracy: 0.9053\n",
      "Epoch 642/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2331 - accuracy: 0.9292 - val_loss: 0.3073 - val_accuracy: 0.9087\n",
      "Epoch 643/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2277 - accuracy: 0.9344 - val_loss: 0.2963 - val_accuracy: 0.9111\n",
      "Epoch 644/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2251 - accuracy: 0.9359 - val_loss: 0.3002 - val_accuracy: 0.9106\n",
      "Epoch 645/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2315 - accuracy: 0.9302 - val_loss: 0.2983 - val_accuracy: 0.9111\n",
      "Epoch 646/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2324 - accuracy: 0.9292 - val_loss: 0.3113 - val_accuracy: 0.9087\n",
      "Epoch 647/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2272 - accuracy: 0.9307 - val_loss: 0.3126 - val_accuracy: 0.9082\n",
      "Epoch 648/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2281 - accuracy: 0.9298 - val_loss: 0.3065 - val_accuracy: 0.9092\n",
      "Epoch 649/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2246 - accuracy: 0.9312 - val_loss: 0.3014 - val_accuracy: 0.9097\n",
      "Epoch 650/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2300 - accuracy: 0.9300 - val_loss: 0.3073 - val_accuracy: 0.9058\n",
      "Epoch 651/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2263 - accuracy: 0.9305 - val_loss: 0.3177 - val_accuracy: 0.9048\n",
      "Epoch 652/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2266 - accuracy: 0.9332 - val_loss: 0.3104 - val_accuracy: 0.9063\n",
      "Epoch 653/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2192 - accuracy: 0.9332 - val_loss: 0.3179 - val_accuracy: 0.9058\n",
      "Epoch 654/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2298 - accuracy: 0.9265 - val_loss: 0.3013 - val_accuracy: 0.9111\n",
      "Epoch 655/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2157 - accuracy: 0.9336 - val_loss: 0.3307 - val_accuracy: 0.9024\n",
      "Epoch 656/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2368 - accuracy: 0.9251 - val_loss: 0.3021 - val_accuracy: 0.9126\n",
      "Epoch 657/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2240 - accuracy: 0.9340 - val_loss: 0.3001 - val_accuracy: 0.9102\n",
      "Epoch 658/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2277 - accuracy: 0.9337 - val_loss: 0.3255 - val_accuracy: 0.9077\n",
      "Epoch 659/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2232 - accuracy: 0.9324 - val_loss: 0.3084 - val_accuracy: 0.9068\n",
      "Epoch 660/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2208 - accuracy: 0.9365 - val_loss: 0.3074 - val_accuracy: 0.9072\n",
      "Epoch 661/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2149 - accuracy: 0.9362 - val_loss: 0.3007 - val_accuracy: 0.9082\n",
      "Epoch 662/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2266 - accuracy: 0.9301 - val_loss: 0.2954 - val_accuracy: 0.9131\n",
      "Epoch 663/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2212 - accuracy: 0.9341 - val_loss: 0.3067 - val_accuracy: 0.9082\n",
      "Epoch 664/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2248 - accuracy: 0.9315 - val_loss: 0.3053 - val_accuracy: 0.9087\n",
      "Epoch 665/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2268 - accuracy: 0.9332 - val_loss: 0.3010 - val_accuracy: 0.9136\n",
      "Epoch 666/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2154 - accuracy: 0.9351 - val_loss: 0.3089 - val_accuracy: 0.9102\n",
      "Epoch 667/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2222 - accuracy: 0.9348 - val_loss: 0.3090 - val_accuracy: 0.9106\n",
      "Epoch 668/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2189 - accuracy: 0.9343 - val_loss: 0.2909 - val_accuracy: 0.9165\n",
      "Epoch 669/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2365 - accuracy: 0.9312 - val_loss: 0.3542 - val_accuracy: 0.8975\n",
      "Epoch 670/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2113 - accuracy: 0.9377 - val_loss: 0.3005 - val_accuracy: 0.9087\n",
      "Epoch 671/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2246 - accuracy: 0.9298 - val_loss: 0.3088 - val_accuracy: 0.9063\n",
      "Epoch 672/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2294 - accuracy: 0.9326 - val_loss: 0.3225 - val_accuracy: 0.9082\n",
      "Epoch 673/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2192 - accuracy: 0.9311 - val_loss: 0.3107 - val_accuracy: 0.9048\n",
      "Epoch 674/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2150 - accuracy: 0.9356 - val_loss: 0.2942 - val_accuracy: 0.9116\n",
      "Epoch 675/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2151 - accuracy: 0.9358 - val_loss: 0.3049 - val_accuracy: 0.9068\n",
      "Epoch 676/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2273 - accuracy: 0.9303 - val_loss: 0.3267 - val_accuracy: 0.9029\n",
      "Epoch 677/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2186 - accuracy: 0.9345 - val_loss: 0.3112 - val_accuracy: 0.9087\n",
      "Epoch 678/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2219 - accuracy: 0.9331 - val_loss: 0.3082 - val_accuracy: 0.9121\n",
      "Epoch 679/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2260 - accuracy: 0.9306 - val_loss: 0.3459 - val_accuracy: 0.8975\n",
      "Epoch 680/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2266 - accuracy: 0.9326 - val_loss: 0.2961 - val_accuracy: 0.9072\n",
      "Epoch 681/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2158 - accuracy: 0.9328 - val_loss: 0.2930 - val_accuracy: 0.9097\n",
      "Epoch 682/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2183 - accuracy: 0.9307 - val_loss: 0.3022 - val_accuracy: 0.9087\n",
      "Epoch 683/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2241 - accuracy: 0.9314 - val_loss: 0.2931 - val_accuracy: 0.9111\n",
      "Epoch 684/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2200 - accuracy: 0.9331 - val_loss: 0.3073 - val_accuracy: 0.9082\n",
      "Epoch 685/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2085 - accuracy: 0.9351 - val_loss: 0.2975 - val_accuracy: 0.9126\n",
      "Epoch 686/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2202 - accuracy: 0.9355 - val_loss: 0.2920 - val_accuracy: 0.9160\n",
      "Epoch 687/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2251 - accuracy: 0.9331 - val_loss: 0.2936 - val_accuracy: 0.9155\n",
      "Epoch 688/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2235 - accuracy: 0.9325 - val_loss: 0.3320 - val_accuracy: 0.9029\n",
      "Epoch 689/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2144 - accuracy: 0.9348 - val_loss: 0.3038 - val_accuracy: 0.9087\n",
      "Epoch 690/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2203 - accuracy: 0.9334 - val_loss: 0.2991 - val_accuracy: 0.9102\n",
      "Epoch 691/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2110 - accuracy: 0.9384 - val_loss: 0.2936 - val_accuracy: 0.9121\n",
      "Epoch 692/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2262 - accuracy: 0.9321 - val_loss: 0.2972 - val_accuracy: 0.9106\n",
      "Epoch 693/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2262 - accuracy: 0.9316 - val_loss: 0.2974 - val_accuracy: 0.9145\n",
      "Epoch 694/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2125 - accuracy: 0.9349 - val_loss: 0.2881 - val_accuracy: 0.9131\n",
      "Epoch 695/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2230 - accuracy: 0.9331 - val_loss: 0.3057 - val_accuracy: 0.9092\n",
      "Epoch 696/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2146 - accuracy: 0.9351 - val_loss: 0.3113 - val_accuracy: 0.9082\n",
      "Epoch 697/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2269 - accuracy: 0.9329 - val_loss: 0.3077 - val_accuracy: 0.9087\n",
      "Epoch 698/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2200 - accuracy: 0.9331 - val_loss: 0.2975 - val_accuracy: 0.9131\n",
      "Epoch 699/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2156 - accuracy: 0.9364 - val_loss: 0.2947 - val_accuracy: 0.9111\n",
      "Epoch 700/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2198 - accuracy: 0.9341 - val_loss: 0.3684 - val_accuracy: 0.8917\n",
      "Epoch 701/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2128 - accuracy: 0.9344 - val_loss: 0.2918 - val_accuracy: 0.9155\n",
      "Epoch 702/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2113 - accuracy: 0.9365 - val_loss: 0.3113 - val_accuracy: 0.9072\n",
      "Epoch 703/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2241 - accuracy: 0.9329 - val_loss: 0.3004 - val_accuracy: 0.9077\n",
      "Epoch 704/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2102 - accuracy: 0.9369 - val_loss: 0.2995 - val_accuracy: 0.9082\n",
      "Epoch 705/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2179 - accuracy: 0.9353 - val_loss: 0.3013 - val_accuracy: 0.9082\n",
      "Epoch 706/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2153 - accuracy: 0.9357 - val_loss: 0.2916 - val_accuracy: 0.9121\n",
      "Epoch 707/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2185 - accuracy: 0.9325 - val_loss: 0.3000 - val_accuracy: 0.9116\n",
      "Epoch 708/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2182 - accuracy: 0.9344 - val_loss: 0.3076 - val_accuracy: 0.9102\n",
      "Epoch 709/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2219 - accuracy: 0.9333 - val_loss: 0.3020 - val_accuracy: 0.9097\n",
      "Epoch 710/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2033 - accuracy: 0.9366 - val_loss: 0.3469 - val_accuracy: 0.8985\n",
      "Epoch 711/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2162 - accuracy: 0.9393 - val_loss: 0.3137 - val_accuracy: 0.9058\n",
      "Epoch 712/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2151 - accuracy: 0.9326 - val_loss: 0.3050 - val_accuracy: 0.9082\n",
      "Epoch 713/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2172 - accuracy: 0.9350 - val_loss: 0.2882 - val_accuracy: 0.9140\n",
      "Epoch 714/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2108 - accuracy: 0.9396 - val_loss: 0.2965 - val_accuracy: 0.9097\n",
      "Epoch 715/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2107 - accuracy: 0.9377 - val_loss: 0.3037 - val_accuracy: 0.9087\n",
      "Epoch 716/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2187 - accuracy: 0.9355 - val_loss: 0.3006 - val_accuracy: 0.9111\n",
      "Epoch 717/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2087 - accuracy: 0.9384 - val_loss: 0.3004 - val_accuracy: 0.9082\n",
      "Epoch 718/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2164 - accuracy: 0.9360 - val_loss: 0.2872 - val_accuracy: 0.9136\n",
      "Epoch 719/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2225 - accuracy: 0.9317 - val_loss: 0.2927 - val_accuracy: 0.9140\n",
      "Epoch 720/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2045 - accuracy: 0.9415 - val_loss: 0.3026 - val_accuracy: 0.9111\n",
      "Epoch 721/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2117 - accuracy: 0.9334 - val_loss: 0.3180 - val_accuracy: 0.9058\n",
      "Epoch 722/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2127 - accuracy: 0.9370 - val_loss: 0.2915 - val_accuracy: 0.9092\n",
      "Epoch 723/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2081 - accuracy: 0.9356 - val_loss: 0.3105 - val_accuracy: 0.9063\n",
      "Epoch 724/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2122 - accuracy: 0.9355 - val_loss: 0.2832 - val_accuracy: 0.9160\n",
      "Epoch 725/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2158 - accuracy: 0.9365 - val_loss: 0.2977 - val_accuracy: 0.9131\n",
      "Epoch 726/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2137 - accuracy: 0.9352 - val_loss: 0.3022 - val_accuracy: 0.9072\n",
      "Epoch 727/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2065 - accuracy: 0.9370 - val_loss: 0.2866 - val_accuracy: 0.9145\n",
      "Epoch 728/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2147 - accuracy: 0.9354 - val_loss: 0.3109 - val_accuracy: 0.9097\n",
      "Epoch 729/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2136 - accuracy: 0.9367 - val_loss: 0.2975 - val_accuracy: 0.9136\n",
      "Epoch 730/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2081 - accuracy: 0.9374 - val_loss: 0.3006 - val_accuracy: 0.9116\n",
      "Epoch 731/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2205 - accuracy: 0.9348 - val_loss: 0.3101 - val_accuracy: 0.9097\n",
      "Epoch 732/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2085 - accuracy: 0.9376 - val_loss: 0.2949 - val_accuracy: 0.9082\n",
      "Epoch 733/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2119 - accuracy: 0.9373 - val_loss: 0.2934 - val_accuracy: 0.9145\n",
      "Epoch 734/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2121 - accuracy: 0.9359 - val_loss: 0.2975 - val_accuracy: 0.9087\n",
      "Epoch 735/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2085 - accuracy: 0.9373 - val_loss: 0.3089 - val_accuracy: 0.9082\n",
      "Epoch 736/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2180 - accuracy: 0.9345 - val_loss: 0.2931 - val_accuracy: 0.9131\n",
      "Epoch 737/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2055 - accuracy: 0.9386 - val_loss: 0.2919 - val_accuracy: 0.9126\n",
      "Epoch 738/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2094 - accuracy: 0.9371 - val_loss: 0.2940 - val_accuracy: 0.9140\n",
      "Epoch 739/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2020 - accuracy: 0.9411 - val_loss: 0.2938 - val_accuracy: 0.9116\n",
      "Epoch 740/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2093 - accuracy: 0.9400 - val_loss: 0.3019 - val_accuracy: 0.9072\n",
      "Epoch 741/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2089 - accuracy: 0.9357 - val_loss: 0.2927 - val_accuracy: 0.9121\n",
      "Epoch 742/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2104 - accuracy: 0.9366 - val_loss: 0.2973 - val_accuracy: 0.9121\n",
      "Epoch 743/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2073 - accuracy: 0.9367 - val_loss: 0.3053 - val_accuracy: 0.9097\n",
      "Epoch 744/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2150 - accuracy: 0.9382 - val_loss: 0.2917 - val_accuracy: 0.9131\n",
      "Epoch 745/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2042 - accuracy: 0.9400 - val_loss: 0.2960 - val_accuracy: 0.9145\n",
      "Epoch 746/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2123 - accuracy: 0.9367 - val_loss: 0.2960 - val_accuracy: 0.9097\n",
      "Epoch 747/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2123 - accuracy: 0.9360 - val_loss: 0.2842 - val_accuracy: 0.9145\n",
      "Epoch 748/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2075 - accuracy: 0.9390 - val_loss: 0.3050 - val_accuracy: 0.9092\n",
      "Epoch 749/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2130 - accuracy: 0.9340 - val_loss: 0.3107 - val_accuracy: 0.9087\n",
      "Epoch 750/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2101 - accuracy: 0.9370 - val_loss: 0.3057 - val_accuracy: 0.9092\n",
      "Epoch 751/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2044 - accuracy: 0.9396 - val_loss: 0.3026 - val_accuracy: 0.9111\n",
      "Epoch 752/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2144 - accuracy: 0.9370 - val_loss: 0.3002 - val_accuracy: 0.9077\n",
      "Epoch 753/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2082 - accuracy: 0.9366 - val_loss: 0.2902 - val_accuracy: 0.9140\n",
      "Epoch 754/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2159 - accuracy: 0.9354 - val_loss: 0.2983 - val_accuracy: 0.9097\n",
      "Epoch 755/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2121 - accuracy: 0.9378 - val_loss: 0.2957 - val_accuracy: 0.9106\n",
      "Epoch 756/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2084 - accuracy: 0.9389 - val_loss: 0.2950 - val_accuracy: 0.9106\n",
      "Epoch 757/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2059 - accuracy: 0.9368 - val_loss: 0.2962 - val_accuracy: 0.9116\n",
      "Epoch 758/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2039 - accuracy: 0.9396 - val_loss: 0.2852 - val_accuracy: 0.9131\n",
      "Epoch 759/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2110 - accuracy: 0.9348 - val_loss: 0.2995 - val_accuracy: 0.9082\n",
      "Epoch 760/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2044 - accuracy: 0.9387 - val_loss: 0.2947 - val_accuracy: 0.9087\n",
      "Epoch 761/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2045 - accuracy: 0.9389 - val_loss: 0.2798 - val_accuracy: 0.9165\n",
      "Epoch 762/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2104 - accuracy: 0.9365 - val_loss: 0.3023 - val_accuracy: 0.9097\n",
      "Epoch 763/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2067 - accuracy: 0.9378 - val_loss: 0.3055 - val_accuracy: 0.9121\n",
      "Epoch 764/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2090 - accuracy: 0.9395 - val_loss: 0.2879 - val_accuracy: 0.9111\n",
      "Epoch 765/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2067 - accuracy: 0.9365 - val_loss: 0.2833 - val_accuracy: 0.9155\n",
      "Epoch 766/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2088 - accuracy: 0.9389 - val_loss: 0.2842 - val_accuracy: 0.9140\n",
      "Epoch 767/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2036 - accuracy: 0.9421 - val_loss: 0.3220 - val_accuracy: 0.9029\n",
      "Epoch 768/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2084 - accuracy: 0.9360 - val_loss: 0.2824 - val_accuracy: 0.9150\n",
      "Epoch 769/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2066 - accuracy: 0.9394 - val_loss: 0.3014 - val_accuracy: 0.9087\n",
      "Epoch 770/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1943 - accuracy: 0.9400 - val_loss: 0.2837 - val_accuracy: 0.9136\n",
      "Epoch 771/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2050 - accuracy: 0.9396 - val_loss: 0.2981 - val_accuracy: 0.9121\n",
      "Epoch 772/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2053 - accuracy: 0.9381 - val_loss: 0.2985 - val_accuracy: 0.9116\n",
      "Epoch 773/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2015 - accuracy: 0.9394 - val_loss: 0.2903 - val_accuracy: 0.9140\n",
      "Epoch 774/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2097 - accuracy: 0.9367 - val_loss: 0.2816 - val_accuracy: 0.9150\n",
      "Epoch 775/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2077 - accuracy: 0.9392 - val_loss: 0.2794 - val_accuracy: 0.9145\n",
      "Epoch 776/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2040 - accuracy: 0.9410 - val_loss: 0.3178 - val_accuracy: 0.9043\n",
      "Epoch 777/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2000 - accuracy: 0.9401 - val_loss: 0.2916 - val_accuracy: 0.9092\n",
      "Epoch 778/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1999 - accuracy: 0.9409 - val_loss: 0.2824 - val_accuracy: 0.9174\n",
      "Epoch 779/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2042 - accuracy: 0.9381 - val_loss: 0.2880 - val_accuracy: 0.9150\n",
      "Epoch 780/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2017 - accuracy: 0.9382 - val_loss: 0.2845 - val_accuracy: 0.9155\n",
      "Epoch 781/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2019 - accuracy: 0.9392 - val_loss: 0.3069 - val_accuracy: 0.9097\n",
      "Epoch 782/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2064 - accuracy: 0.9339 - val_loss: 0.2834 - val_accuracy: 0.9145\n",
      "Epoch 783/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2024 - accuracy: 0.9381 - val_loss: 0.3144 - val_accuracy: 0.9043\n",
      "Epoch 784/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2045 - accuracy: 0.9410 - val_loss: 0.3095 - val_accuracy: 0.9077\n",
      "Epoch 785/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2024 - accuracy: 0.9427 - val_loss: 0.2846 - val_accuracy: 0.9136\n",
      "Epoch 786/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2040 - accuracy: 0.9386 - val_loss: 0.2957 - val_accuracy: 0.9136\n",
      "Epoch 787/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2033 - accuracy: 0.9392 - val_loss: 0.3106 - val_accuracy: 0.9048\n",
      "Epoch 788/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2043 - accuracy: 0.9381 - val_loss: 0.2900 - val_accuracy: 0.9194\n",
      "Epoch 789/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2006 - accuracy: 0.9373 - val_loss: 0.2879 - val_accuracy: 0.9155\n",
      "Epoch 790/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2037 - accuracy: 0.9390 - val_loss: 0.2928 - val_accuracy: 0.9189\n",
      "Epoch 791/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1983 - accuracy: 0.9399 - val_loss: 0.2840 - val_accuracy: 0.9155\n",
      "Epoch 792/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2048 - accuracy: 0.9373 - val_loss: 0.2823 - val_accuracy: 0.9140\n",
      "Epoch 793/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1987 - accuracy: 0.9389 - val_loss: 0.2853 - val_accuracy: 0.9126\n",
      "Epoch 794/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1997 - accuracy: 0.9412 - val_loss: 0.2903 - val_accuracy: 0.9145\n",
      "Epoch 795/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1940 - accuracy: 0.9438 - val_loss: 0.2929 - val_accuracy: 0.9106\n",
      "Epoch 796/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1974 - accuracy: 0.9388 - val_loss: 0.2905 - val_accuracy: 0.9136\n",
      "Epoch 797/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1994 - accuracy: 0.9392 - val_loss: 0.3264 - val_accuracy: 0.9000\n",
      "Epoch 798/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2047 - accuracy: 0.9370 - val_loss: 0.2830 - val_accuracy: 0.9145\n",
      "Epoch 799/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2004 - accuracy: 0.9378 - val_loss: 0.2797 - val_accuracy: 0.9160\n",
      "Epoch 800/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2033 - accuracy: 0.9381 - val_loss: 0.2852 - val_accuracy: 0.9165\n",
      "Epoch 801/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1957 - accuracy: 0.9420 - val_loss: 0.2907 - val_accuracy: 0.9121\n",
      "Epoch 802/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1977 - accuracy: 0.9379 - val_loss: 0.2828 - val_accuracy: 0.9150\n",
      "Epoch 803/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2005 - accuracy: 0.9399 - val_loss: 0.2988 - val_accuracy: 0.9082\n",
      "Epoch 804/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2004 - accuracy: 0.9403 - val_loss: 0.2966 - val_accuracy: 0.9082\n",
      "Epoch 805/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2019 - accuracy: 0.9394 - val_loss: 0.2924 - val_accuracy: 0.9102\n",
      "Epoch 806/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1972 - accuracy: 0.9404 - val_loss: 0.3126 - val_accuracy: 0.9034\n",
      "Epoch 807/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2012 - accuracy: 0.9377 - val_loss: 0.3006 - val_accuracy: 0.9097\n",
      "Epoch 808/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1965 - accuracy: 0.9407 - val_loss: 0.3079 - val_accuracy: 0.9082\n",
      "Epoch 809/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1986 - accuracy: 0.9399 - val_loss: 0.2979 - val_accuracy: 0.9077\n",
      "Epoch 810/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2009 - accuracy: 0.9384 - val_loss: 0.2794 - val_accuracy: 0.9155\n",
      "Epoch 811/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1952 - accuracy: 0.9439 - val_loss: 0.3370 - val_accuracy: 0.9019\n",
      "Epoch 812/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1989 - accuracy: 0.9382 - val_loss: 0.2895 - val_accuracy: 0.9136\n",
      "Epoch 813/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1983 - accuracy: 0.9416 - val_loss: 0.2885 - val_accuracy: 0.9131\n",
      "Epoch 814/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1986 - accuracy: 0.9410 - val_loss: 0.2961 - val_accuracy: 0.9106\n",
      "Epoch 815/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2069 - accuracy: 0.9381 - val_loss: 0.2975 - val_accuracy: 0.9111\n",
      "Epoch 816/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1965 - accuracy: 0.9407 - val_loss: 0.2829 - val_accuracy: 0.9155\n",
      "Epoch 817/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1972 - accuracy: 0.9387 - val_loss: 0.2839 - val_accuracy: 0.9160\n",
      "Epoch 818/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2023 - accuracy: 0.9380 - val_loss: 0.2873 - val_accuracy: 0.9150\n",
      "Epoch 819/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1980 - accuracy: 0.9423 - val_loss: 0.2939 - val_accuracy: 0.9160\n",
      "Epoch 820/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1960 - accuracy: 0.9403 - val_loss: 0.2957 - val_accuracy: 0.9136\n",
      "Epoch 821/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1999 - accuracy: 0.9406 - val_loss: 0.2812 - val_accuracy: 0.9155\n",
      "Epoch 822/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1967 - accuracy: 0.9425 - val_loss: 0.2893 - val_accuracy: 0.9126\n",
      "Epoch 823/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1957 - accuracy: 0.9407 - val_loss: 0.3205 - val_accuracy: 0.9029\n",
      "Epoch 824/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1960 - accuracy: 0.9429 - val_loss: 0.2937 - val_accuracy: 0.9111\n",
      "Epoch 825/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1916 - accuracy: 0.9416 - val_loss: 0.3058 - val_accuracy: 0.9097\n",
      "Epoch 826/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2028 - accuracy: 0.9368 - val_loss: 0.2802 - val_accuracy: 0.9150\n",
      "Epoch 827/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1940 - accuracy: 0.9416 - val_loss: 0.3133 - val_accuracy: 0.9053\n",
      "Epoch 828/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1981 - accuracy: 0.9395 - val_loss: 0.2853 - val_accuracy: 0.9131\n",
      "Epoch 829/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1896 - accuracy: 0.9464 - val_loss: 0.2889 - val_accuracy: 0.9106\n",
      "Epoch 830/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1907 - accuracy: 0.9426 - val_loss: 0.2962 - val_accuracy: 0.9087\n",
      "Epoch 831/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2047 - accuracy: 0.9371 - val_loss: 0.2952 - val_accuracy: 0.9160\n",
      "Epoch 832/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1970 - accuracy: 0.9393 - val_loss: 0.2901 - val_accuracy: 0.9111\n",
      "Epoch 833/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2010 - accuracy: 0.9402 - val_loss: 0.2736 - val_accuracy: 0.9169\n",
      "Epoch 834/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2086 - accuracy: 0.9367 - val_loss: 0.2764 - val_accuracy: 0.9208\n",
      "Epoch 835/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1853 - accuracy: 0.9432 - val_loss: 0.2847 - val_accuracy: 0.9155\n",
      "Epoch 836/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1974 - accuracy: 0.9393 - val_loss: 0.2777 - val_accuracy: 0.9150\n",
      "Epoch 837/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1935 - accuracy: 0.9420 - val_loss: 0.3051 - val_accuracy: 0.9097\n",
      "Epoch 838/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1989 - accuracy: 0.9421 - val_loss: 0.2899 - val_accuracy: 0.9145\n",
      "Epoch 839/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1900 - accuracy: 0.9414 - val_loss: 0.3095 - val_accuracy: 0.9077\n",
      "Epoch 840/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2071 - accuracy: 0.9378 - val_loss: 0.3014 - val_accuracy: 0.9106\n",
      "Epoch 841/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.2004 - accuracy: 0.9368 - val_loss: 0.2850 - val_accuracy: 0.9165\n",
      "Epoch 842/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1851 - accuracy: 0.9461 - val_loss: 0.2826 - val_accuracy: 0.9140\n",
      "Epoch 843/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2008 - accuracy: 0.9406 - val_loss: 0.2719 - val_accuracy: 0.9194\n",
      "Epoch 844/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1864 - accuracy: 0.9443 - val_loss: 0.2749 - val_accuracy: 0.9150\n",
      "Epoch 845/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1939 - accuracy: 0.9385 - val_loss: 0.2831 - val_accuracy: 0.9165\n",
      "Epoch 846/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1881 - accuracy: 0.9433 - val_loss: 0.2844 - val_accuracy: 0.9136\n",
      "Epoch 847/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2009 - accuracy: 0.9397 - val_loss: 0.3086 - val_accuracy: 0.9092\n",
      "Epoch 848/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1946 - accuracy: 0.9394 - val_loss: 0.2864 - val_accuracy: 0.9165\n",
      "Epoch 849/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1910 - accuracy: 0.9433 - val_loss: 0.2906 - val_accuracy: 0.9111\n",
      "Epoch 850/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1946 - accuracy: 0.9405 - val_loss: 0.3099 - val_accuracy: 0.9116\n",
      "Epoch 851/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1982 - accuracy: 0.9397 - val_loss: 0.3045 - val_accuracy: 0.9102\n",
      "Epoch 852/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1868 - accuracy: 0.9426 - val_loss: 0.2952 - val_accuracy: 0.9169\n",
      "Epoch 853/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1908 - accuracy: 0.9455 - val_loss: 0.2821 - val_accuracy: 0.9169\n",
      "Epoch 854/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1980 - accuracy: 0.9412 - val_loss: 0.2741 - val_accuracy: 0.9199\n",
      "Epoch 855/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1935 - accuracy: 0.9405 - val_loss: 0.2894 - val_accuracy: 0.9126\n",
      "Epoch 856/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1882 - accuracy: 0.9433 - val_loss: 0.2778 - val_accuracy: 0.9179\n",
      "Epoch 857/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2041 - accuracy: 0.9362 - val_loss: 0.2920 - val_accuracy: 0.9131\n",
      "Epoch 858/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1893 - accuracy: 0.9425 - val_loss: 0.2771 - val_accuracy: 0.9160\n",
      "Epoch 859/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1955 - accuracy: 0.9433 - val_loss: 0.2877 - val_accuracy: 0.9131\n",
      "Epoch 860/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1930 - accuracy: 0.9404 - val_loss: 0.2871 - val_accuracy: 0.9121\n",
      "Epoch 861/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1987 - accuracy: 0.9407 - val_loss: 0.2712 - val_accuracy: 0.9165\n",
      "Epoch 862/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1878 - accuracy: 0.9433 - val_loss: 0.2800 - val_accuracy: 0.9174\n",
      "Epoch 863/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1901 - accuracy: 0.9420 - val_loss: 0.2711 - val_accuracy: 0.9199\n",
      "Epoch 864/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1824 - accuracy: 0.9465 - val_loss: 0.2832 - val_accuracy: 0.9155\n",
      "Epoch 865/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1941 - accuracy: 0.9397 - val_loss: 0.2903 - val_accuracy: 0.9140\n",
      "Epoch 866/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1945 - accuracy: 0.9435 - val_loss: 0.2758 - val_accuracy: 0.9174\n",
      "Epoch 867/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1840 - accuracy: 0.9439 - val_loss: 0.3036 - val_accuracy: 0.9106\n",
      "Epoch 868/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2004 - accuracy: 0.9368 - val_loss: 0.2870 - val_accuracy: 0.9131\n",
      "Epoch 869/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1913 - accuracy: 0.9418 - val_loss: 0.2850 - val_accuracy: 0.9136\n",
      "Epoch 870/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1831 - accuracy: 0.9432 - val_loss: 0.2852 - val_accuracy: 0.9150\n",
      "Epoch 871/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1918 - accuracy: 0.9395 - val_loss: 0.2723 - val_accuracy: 0.9189\n",
      "Epoch 872/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1992 - accuracy: 0.9393 - val_loss: 0.2916 - val_accuracy: 0.9136\n",
      "Epoch 873/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1862 - accuracy: 0.9403 - val_loss: 0.2825 - val_accuracy: 0.9126\n",
      "Epoch 874/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1892 - accuracy: 0.9425 - val_loss: 0.2870 - val_accuracy: 0.9126\n",
      "Epoch 875/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1917 - accuracy: 0.9399 - val_loss: 0.2881 - val_accuracy: 0.9140\n",
      "Epoch 876/1000\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1946 - accuracy: 0.9410 - val_loss: 0.2780 - val_accuracy: 0.9126\n",
      "Epoch 877/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1818 - accuracy: 0.9446 - val_loss: 0.3049 - val_accuracy: 0.9111\n",
      "Epoch 878/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1899 - accuracy: 0.9435 - val_loss: 0.2805 - val_accuracy: 0.9131\n",
      "Epoch 879/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1877 - accuracy: 0.9439 - val_loss: 0.2812 - val_accuracy: 0.9160\n",
      "Epoch 880/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2001 - accuracy: 0.9361 - val_loss: 0.2757 - val_accuracy: 0.9165\n",
      "Epoch 881/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1786 - accuracy: 0.9470 - val_loss: 0.2808 - val_accuracy: 0.9121\n",
      "Epoch 882/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.2002 - accuracy: 0.9392 - val_loss: 0.2823 - val_accuracy: 0.9145\n",
      "Epoch 883/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1724 - accuracy: 0.9503 - val_loss: 0.2779 - val_accuracy: 0.9160\n",
      "Epoch 884/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1874 - accuracy: 0.9425 - val_loss: 0.2814 - val_accuracy: 0.9102\n",
      "Epoch 885/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1915 - accuracy: 0.9415 - val_loss: 0.2949 - val_accuracy: 0.9121\n",
      "Epoch 886/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1953 - accuracy: 0.9418 - val_loss: 0.2831 - val_accuracy: 0.9136\n",
      "Epoch 887/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1885 - accuracy: 0.9436 - val_loss: 0.2751 - val_accuracy: 0.9169\n",
      "Epoch 888/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1917 - accuracy: 0.9418 - val_loss: 0.2830 - val_accuracy: 0.9140\n",
      "Epoch 889/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1852 - accuracy: 0.9423 - val_loss: 0.2778 - val_accuracy: 0.9136\n",
      "Epoch 890/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1860 - accuracy: 0.9435 - val_loss: 0.2777 - val_accuracy: 0.9131\n",
      "Epoch 891/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1818 - accuracy: 0.9440 - val_loss: 0.2754 - val_accuracy: 0.9184\n",
      "Epoch 892/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1926 - accuracy: 0.9429 - val_loss: 0.2969 - val_accuracy: 0.9131\n",
      "Epoch 893/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1903 - accuracy: 0.9431 - val_loss: 0.2847 - val_accuracy: 0.9150\n",
      "Epoch 894/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1893 - accuracy: 0.9417 - val_loss: 0.2858 - val_accuracy: 0.9140\n",
      "Epoch 895/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1861 - accuracy: 0.9416 - val_loss: 0.2786 - val_accuracy: 0.9150\n",
      "Epoch 896/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1852 - accuracy: 0.9429 - val_loss: 0.2977 - val_accuracy: 0.9136\n",
      "Epoch 897/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1843 - accuracy: 0.9444 - val_loss: 0.2776 - val_accuracy: 0.9174\n",
      "Epoch 898/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1905 - accuracy: 0.9405 - val_loss: 0.2806 - val_accuracy: 0.9160\n",
      "Epoch 899/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1880 - accuracy: 0.9435 - val_loss: 0.2767 - val_accuracy: 0.9145\n",
      "Epoch 900/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1874 - accuracy: 0.9438 - val_loss: 0.2732 - val_accuracy: 0.9165\n",
      "Epoch 901/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1845 - accuracy: 0.9450 - val_loss: 0.2826 - val_accuracy: 0.9136\n",
      "Epoch 902/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1888 - accuracy: 0.9414 - val_loss: 0.2890 - val_accuracy: 0.9165\n",
      "Epoch 903/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1847 - accuracy: 0.9472 - val_loss: 0.2714 - val_accuracy: 0.9169\n",
      "Epoch 904/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1847 - accuracy: 0.9444 - val_loss: 0.2843 - val_accuracy: 0.9140\n",
      "Epoch 905/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1898 - accuracy: 0.9388 - val_loss: 0.2805 - val_accuracy: 0.9169\n",
      "Epoch 906/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1891 - accuracy: 0.9455 - val_loss: 0.2719 - val_accuracy: 0.9165\n",
      "Epoch 907/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1862 - accuracy: 0.9418 - val_loss: 0.3073 - val_accuracy: 0.9106\n",
      "Epoch 908/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1835 - accuracy: 0.9479 - val_loss: 0.2962 - val_accuracy: 0.9106\n",
      "Epoch 909/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1846 - accuracy: 0.9449 - val_loss: 0.2734 - val_accuracy: 0.9169\n",
      "Epoch 910/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1901 - accuracy: 0.9419 - val_loss: 0.2740 - val_accuracy: 0.9136\n",
      "Epoch 911/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1866 - accuracy: 0.9432 - val_loss: 0.2980 - val_accuracy: 0.9102\n",
      "Epoch 912/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1813 - accuracy: 0.9429 - val_loss: 0.3027 - val_accuracy: 0.9092\n",
      "Epoch 913/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1851 - accuracy: 0.9450 - val_loss: 0.2820 - val_accuracy: 0.9155\n",
      "Epoch 914/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1870 - accuracy: 0.9427 - val_loss: 0.2770 - val_accuracy: 0.9174\n",
      "Epoch 915/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1811 - accuracy: 0.9428 - val_loss: 0.2746 - val_accuracy: 0.9165\n",
      "Epoch 916/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1894 - accuracy: 0.9447 - val_loss: 0.2710 - val_accuracy: 0.9155\n",
      "Epoch 917/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1851 - accuracy: 0.9444 - val_loss: 0.2770 - val_accuracy: 0.9189\n",
      "Epoch 918/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1864 - accuracy: 0.9446 - val_loss: 0.3062 - val_accuracy: 0.9102\n",
      "Epoch 919/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1853 - accuracy: 0.9451 - val_loss: 0.2736 - val_accuracy: 0.9155\n",
      "Epoch 920/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1841 - accuracy: 0.9454 - val_loss: 0.2690 - val_accuracy: 0.9169\n",
      "Epoch 921/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1837 - accuracy: 0.9440 - val_loss: 0.2742 - val_accuracy: 0.9150\n",
      "Epoch 922/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1827 - accuracy: 0.9449 - val_loss: 0.2784 - val_accuracy: 0.9145\n",
      "Epoch 923/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1842 - accuracy: 0.9458 - val_loss: 0.2717 - val_accuracy: 0.9150\n",
      "Epoch 924/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1811 - accuracy: 0.9438 - val_loss: 0.2757 - val_accuracy: 0.9160\n",
      "Epoch 925/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1826 - accuracy: 0.9428 - val_loss: 0.2946 - val_accuracy: 0.9140\n",
      "Epoch 926/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1857 - accuracy: 0.9438 - val_loss: 0.2736 - val_accuracy: 0.9179\n",
      "Epoch 927/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1923 - accuracy: 0.9394 - val_loss: 0.2746 - val_accuracy: 0.9160\n",
      "Epoch 928/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1788 - accuracy: 0.9461 - val_loss: 0.2815 - val_accuracy: 0.9179\n",
      "Epoch 929/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1753 - accuracy: 0.9475 - val_loss: 0.2815 - val_accuracy: 0.9194\n",
      "Epoch 930/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1880 - accuracy: 0.9420 - val_loss: 0.2692 - val_accuracy: 0.9145\n",
      "Epoch 931/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1805 - accuracy: 0.9445 - val_loss: 0.2812 - val_accuracy: 0.9131\n",
      "Epoch 932/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1873 - accuracy: 0.9429 - val_loss: 0.2782 - val_accuracy: 0.9150\n",
      "Epoch 933/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1826 - accuracy: 0.9443 - val_loss: 0.2757 - val_accuracy: 0.9194\n",
      "Epoch 934/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1790 - accuracy: 0.9462 - val_loss: 0.2686 - val_accuracy: 0.9165\n",
      "Epoch 935/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1787 - accuracy: 0.9447 - val_loss: 0.3320 - val_accuracy: 0.9024\n",
      "Epoch 936/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1816 - accuracy: 0.9468 - val_loss: 0.2829 - val_accuracy: 0.9131\n",
      "Epoch 937/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1838 - accuracy: 0.9454 - val_loss: 0.2773 - val_accuracy: 0.9179\n",
      "Epoch 938/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1797 - accuracy: 0.9483 - val_loss: 0.2737 - val_accuracy: 0.9169\n",
      "Epoch 939/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1866 - accuracy: 0.9465 - val_loss: 0.2795 - val_accuracy: 0.9179\n",
      "Epoch 940/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1811 - accuracy: 0.9443 - val_loss: 0.2730 - val_accuracy: 0.9169\n",
      "Epoch 941/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1795 - accuracy: 0.9468 - val_loss: 0.2786 - val_accuracy: 0.9126\n",
      "Epoch 942/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1835 - accuracy: 0.9466 - val_loss: 0.2731 - val_accuracy: 0.9155\n",
      "Epoch 943/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1819 - accuracy: 0.9458 - val_loss: 0.2804 - val_accuracy: 0.9179\n",
      "Epoch 944/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1839 - accuracy: 0.9437 - val_loss: 0.2755 - val_accuracy: 0.9165\n",
      "Epoch 945/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1810 - accuracy: 0.9422 - val_loss: 0.2705 - val_accuracy: 0.9155\n",
      "Epoch 946/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1854 - accuracy: 0.9432 - val_loss: 0.2709 - val_accuracy: 0.9184\n",
      "Epoch 947/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1737 - accuracy: 0.9465 - val_loss: 0.2765 - val_accuracy: 0.9169\n",
      "Epoch 948/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1818 - accuracy: 0.9443 - val_loss: 0.2752 - val_accuracy: 0.9165\n",
      "Epoch 949/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1792 - accuracy: 0.9453 - val_loss: 0.2740 - val_accuracy: 0.9169\n",
      "Epoch 950/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1835 - accuracy: 0.9449 - val_loss: 0.2913 - val_accuracy: 0.9155\n",
      "Epoch 951/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1830 - accuracy: 0.9436 - val_loss: 0.2752 - val_accuracy: 0.9150\n",
      "Epoch 952/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1809 - accuracy: 0.9422 - val_loss: 0.2690 - val_accuracy: 0.9169\n",
      "Epoch 953/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1772 - accuracy: 0.9470 - val_loss: 0.2930 - val_accuracy: 0.9102\n",
      "Epoch 954/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1805 - accuracy: 0.9444 - val_loss: 0.2733 - val_accuracy: 0.9199\n",
      "Epoch 955/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1818 - accuracy: 0.9450 - val_loss: 0.2714 - val_accuracy: 0.9174\n",
      "Epoch 956/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1808 - accuracy: 0.9439 - val_loss: 0.2690 - val_accuracy: 0.9145\n",
      "Epoch 957/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1808 - accuracy: 0.9471 - val_loss: 0.2797 - val_accuracy: 0.9136\n",
      "Epoch 958/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1758 - accuracy: 0.9475 - val_loss: 0.2745 - val_accuracy: 0.9169\n",
      "Epoch 959/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1822 - accuracy: 0.9465 - val_loss: 0.3099 - val_accuracy: 0.9082\n",
      "Epoch 960/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1809 - accuracy: 0.9427 - val_loss: 0.2728 - val_accuracy: 0.9194\n",
      "Epoch 961/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1775 - accuracy: 0.9465 - val_loss: 0.2685 - val_accuracy: 0.9184\n",
      "Epoch 962/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1793 - accuracy: 0.9443 - val_loss: 0.2803 - val_accuracy: 0.9150\n",
      "Epoch 963/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1767 - accuracy: 0.9467 - val_loss: 0.2914 - val_accuracy: 0.9155\n",
      "Epoch 964/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1797 - accuracy: 0.9472 - val_loss: 0.2720 - val_accuracy: 0.9194\n",
      "Epoch 965/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1804 - accuracy: 0.9452 - val_loss: 0.2900 - val_accuracy: 0.9131\n",
      "Epoch 966/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1831 - accuracy: 0.9446 - val_loss: 0.2655 - val_accuracy: 0.9194\n",
      "Epoch 967/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1832 - accuracy: 0.9431 - val_loss: 0.2821 - val_accuracy: 0.9145\n",
      "Epoch 968/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1715 - accuracy: 0.9478 - val_loss: 0.2745 - val_accuracy: 0.9184\n",
      "Epoch 969/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1808 - accuracy: 0.9450 - val_loss: 0.2913 - val_accuracy: 0.9136\n",
      "Epoch 970/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1755 - accuracy: 0.9498 - val_loss: 0.2775 - val_accuracy: 0.9194\n",
      "Epoch 971/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1771 - accuracy: 0.9456 - val_loss: 0.2674 - val_accuracy: 0.9213\n",
      "Epoch 972/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1814 - accuracy: 0.9433 - val_loss: 0.2622 - val_accuracy: 0.9184\n",
      "Epoch 973/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1756 - accuracy: 0.9490 - val_loss: 0.2763 - val_accuracy: 0.9150\n",
      "Epoch 974/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1758 - accuracy: 0.9465 - val_loss: 0.2727 - val_accuracy: 0.9174\n",
      "Epoch 975/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1856 - accuracy: 0.9438 - val_loss: 0.2635 - val_accuracy: 0.9194\n",
      "Epoch 976/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1772 - accuracy: 0.9483 - val_loss: 0.2783 - val_accuracy: 0.9165\n",
      "Epoch 977/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1770 - accuracy: 0.9454 - val_loss: 0.2729 - val_accuracy: 0.9174\n",
      "Epoch 978/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1764 - accuracy: 0.9493 - val_loss: 0.2699 - val_accuracy: 0.9136\n",
      "Epoch 979/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1808 - accuracy: 0.9457 - val_loss: 0.2773 - val_accuracy: 0.9160\n",
      "Epoch 980/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1823 - accuracy: 0.9439 - val_loss: 0.2707 - val_accuracy: 0.9208\n",
      "Epoch 981/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1732 - accuracy: 0.9495 - val_loss: 0.2696 - val_accuracy: 0.9160\n",
      "Epoch 982/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1794 - accuracy: 0.9470 - val_loss: 0.2680 - val_accuracy: 0.9189\n",
      "Epoch 983/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1771 - accuracy: 0.9456 - val_loss: 0.2704 - val_accuracy: 0.9179\n",
      "Epoch 984/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1780 - accuracy: 0.9456 - val_loss: 0.2985 - val_accuracy: 0.9121\n",
      "Epoch 985/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1726 - accuracy: 0.9458 - val_loss: 0.2844 - val_accuracy: 0.9174\n",
      "Epoch 986/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1766 - accuracy: 0.9482 - val_loss: 0.2784 - val_accuracy: 0.9208\n",
      "Epoch 987/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1824 - accuracy: 0.9448 - val_loss: 0.2714 - val_accuracy: 0.9199\n",
      "Epoch 988/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1785 - accuracy: 0.9467 - val_loss: 0.2772 - val_accuracy: 0.9169\n",
      "Epoch 989/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1639 - accuracy: 0.9522 - val_loss: 0.2744 - val_accuracy: 0.9199\n",
      "Epoch 990/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1810 - accuracy: 0.9465 - val_loss: 0.2766 - val_accuracy: 0.9155\n",
      "Epoch 991/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1818 - accuracy: 0.9445 - val_loss: 0.2673 - val_accuracy: 0.9194\n",
      "Epoch 992/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1808 - accuracy: 0.9444 - val_loss: 0.3111 - val_accuracy: 0.9121\n",
      "Epoch 993/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1765 - accuracy: 0.9468 - val_loss: 0.2688 - val_accuracy: 0.9194\n",
      "Epoch 994/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1741 - accuracy: 0.9472 - val_loss: 0.2756 - val_accuracy: 0.9160\n",
      "Epoch 995/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1744 - accuracy: 0.9494 - val_loss: 0.2668 - val_accuracy: 0.9169\n",
      "Epoch 996/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1759 - accuracy: 0.9440 - val_loss: 0.2645 - val_accuracy: 0.9179\n",
      "Epoch 997/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1708 - accuracy: 0.9472 - val_loss: 0.2692 - val_accuracy: 0.9184\n",
      "Epoch 998/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1833 - accuracy: 0.9438 - val_loss: 0.2796 - val_accuracy: 0.9150\n",
      "Epoch 999/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1775 - accuracy: 0.9455 - val_loss: 0.2965 - val_accuracy: 0.9145\n",
      "Epoch 1000/1000\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.1670 - accuracy: 0.9476 - val_loss: 0.2697 - val_accuracy: 0.9194\n",
      "Training took 318.89353686968485 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n"
     ]
    }
   ],
   "source": [
    "sim.UpdateParams(totEpochs=1000)\n",
    "sim.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          asplanchna       0.92      0.96      0.94        68\n",
      "        asterionella       0.89      0.86      0.87        36\n",
      "             bosmina       0.62      0.62      0.62        13\n",
      "            ceratium       0.86      0.91      0.88        33\n",
      "           chaoborus       0.00      0.00      0.00         1\n",
      "          conochilus       0.88      0.88      0.88         8\n",
      "             cyclops       0.85      0.95      0.90       107\n",
      "             daphnia       0.91      0.85      0.88       113\n",
      "        diaphanosoma       0.92      0.98      0.95       221\n",
      "           dinobryon       0.97      0.99      0.98       593\n",
      "                dirt       0.50      0.25      0.33        20\n",
      "         eudiaptomus       0.91      0.78      0.84        93\n",
      "            filament       0.88      0.97      0.93        38\n",
      "                fish       0.66      0.72      0.69        32\n",
      "          fragilaria       0.97      0.95      0.96        38\n",
      "         kellikottia       1.00      0.94      0.97        36\n",
      "keratella_cochlearis       0.43      0.67      0.52         9\n",
      "  keratella_quadrata       0.93      0.87      0.90        45\n",
      "           leptodora       0.80      0.72      0.76        39\n",
      "         maybe_cyano       0.79      0.96      0.87        28\n",
      "            nauplius       0.98      0.98      0.98       192\n",
      "        paradileptus       0.93      0.81      0.87        16\n",
      "            rotifers       0.64      0.67      0.65        27\n",
      "         trichocerca       0.90      0.96      0.92        45\n",
      "             unknown       0.86      0.35      0.50        34\n",
      "    unknown_plankton       0.33      0.25      0.29        12\n",
      "            uroglena       1.00      1.00      1.00       162\n",
      "\n",
      "            accuracy                           0.92      2059\n",
      "           macro avg       0.79      0.77      0.77      2059\n",
      "        weighted avg       0.92      0.92      0.92      2059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sim.Report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract manually the training loss corresponding to the best weights, so that we can make sure that restarting the simulation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training loss: 2.3451321361646857\n",
      "Best    training loss: 0.18138801154285553\n"
     ]
    }
   ],
   "source": [
    "def BestLoss(history):\n",
    "    ''' Returns the training loss of the point where the validation loss was minimal'''\n",
    "    return history['loss'][np.argmin(history['val_loss'])]\n",
    "def InitLoss(history):\n",
    "    ''' Returns the training loss of the point where the validation loss was minimal'''\n",
    "    return history['loss'][0]\n",
    "\n",
    "initLoss = InitLoss(sim.history.history)\n",
    "bestLoss = BestLoss(sim.history.history)\n",
    "\n",
    "print('Initial training loss:',initLoss)\n",
    "print('Best    training loss:',bestLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Weights and keep training\n",
    "Now we load the best weights, just to show that the loss does not start from scratch again.\n",
    "If `sim.params.load` is set to `None`, the simulation starts from scratch. Otherwise, it can be set to the path to saved weights (as in this example).\n",
    "I also show how to play around with some input parameters.\n",
    "\n",
    "In the current setting, we expect that, if the learning rate is not too big, the loss should still decrease with respect to BestLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs for the first run: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n",
      "Loading only the weights\n",
      "Epoch 1001/1005\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1827 - accuracy: 0.9448 - val_loss: 0.2667 - val_accuracy: 0.9189\n",
      "Epoch 1002/1005\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1796 - accuracy: 0.9443 - val_loss: 0.2877 - val_accuracy: 0.9136\n",
      "Epoch 1003/1005\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1746 - accuracy: 0.9478 - val_loss: 0.2785 - val_accuracy: 0.9174\n",
      "Epoch 1004/1005\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1803 - accuracy: 0.9456 - val_loss: 0.2851 - val_accuracy: 0.9131\n",
      "Epoch 1005/1005\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.1783 - accuracy: 0.9444 - val_loss: 0.2873 - val_accuracy: 0.9140\n",
      "Training took 1.6160561203956605 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n",
      "Epochs for the second run: [1000, 1001, 1002, 1003, 1004]\n"
     ]
    }
   ],
   "source": [
    "# Load the weights\n",
    "sim.params.load=sim.params.outpath+'/bestweights.hdf5'\n",
    "\n",
    "# Set initial epoch to the end of the previous run, and extend the total number of epochs (otherwise it won't run)\n",
    "sim.params.initial_epoch=sim.history.epoch[-1]+1 if len(sim.history.epoch)>0 else 0\n",
    "sim.params.totEpochs=sim.params.initial_epoch+5\n",
    "\n",
    "print('Epochs for the first run:', sim.history.epoch)\n",
    "sim.Train()\n",
    "print('Epochs for the second run:', sim.history.epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the initial loss with the best loss of the previous run. The new one should be smaller or equal, since we expect the loss to be decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This quantity should be negative in normal conditions: -2.16374412462183\n",
      "This quantity should be non negative in normal conditions: 0.0002857116985467145\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          asplanchna       0.93      0.94      0.93        68\n",
      "        asterionella       0.97      0.83      0.90        36\n",
      "             bosmina       0.54      0.54      0.54        13\n",
      "            ceratium       0.79      0.94      0.86        33\n",
      "           chaoborus       0.00      0.00      0.00         1\n",
      "          conochilus       0.88      0.88      0.88         8\n",
      "             cyclops       0.94      0.85      0.89       107\n",
      "             daphnia       0.88      0.85      0.86       113\n",
      "        diaphanosoma       0.92      0.98      0.95       221\n",
      "           dinobryon       0.97      1.00      0.98       593\n",
      "                dirt       0.41      0.35      0.38        20\n",
      "         eudiaptomus       0.84      0.82      0.83        93\n",
      "            filament       0.90      0.97      0.94        38\n",
      "                fish       0.53      0.72      0.61        32\n",
      "          fragilaria       0.92      0.95      0.94        38\n",
      "         kellikottia       0.97      0.94      0.96        36\n",
      "keratella_cochlearis       0.38      0.89      0.53         9\n",
      "  keratella_quadrata       0.93      0.93      0.93        45\n",
      "           leptodora       0.79      0.79      0.79        39\n",
      "         maybe_cyano       0.83      0.89      0.86        28\n",
      "            nauplius       0.99      0.96      0.98       192\n",
      "        paradileptus       1.00      0.69      0.81        16\n",
      "            rotifers       0.68      0.56      0.61        27\n",
      "         trichocerca       0.95      0.91      0.93        45\n",
      "             unknown       0.81      0.38      0.52        34\n",
      "    unknown_plankton       0.33      0.25      0.29        12\n",
      "            uroglena       1.00      0.99      1.00       162\n",
      "\n",
      "            accuracy                           0.91      2059\n",
      "           macro avg       0.78      0.77      0.77      2059\n",
      "        weighted avg       0.92      0.91      0.91      2059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Compare checkpointed loss with loss at the very beginning of the simulation\n",
    "print('This quantity should be negative in normal conditions:',bestLoss-initLoss)\n",
    "\n",
    "# Compare checkpointed loss with loss at the beginning of the run after the checkpoint (i.e. one epoch later)\n",
    "print('This quantity should be non negative in normal conditions:',bestLoss-InitLoss(sim.history.history))\n",
    "\n",
    "sim.Report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Other Simulation from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model, parameters and classes that were generated in the previous simulation.\n",
    "\n",
    "Of course, we could just get them from `sim`, but here we are simulating that this is an entirely independent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Arguments for generation of the model ----------\n",
      "out_example/params.txt contains the following parameters:\n",
      "Namespace(L=128, aug=True, bs=32, class_select=None, datakind='image', datapath='./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28//', dropout=None, earlyStopping=100, initial_epoch=0, layers=[256, 128], load=None, lr=5e-05, model='conv2', model_feat='mlp', model_image='mlp', opt='sgd', outpath='out_example', plot=False, saveModelName='keras_model.h5', testSplit=0.2, totEpochs=1000, training_data=True, ttkind='image', verbose=False)\n",
      "\n",
      "-----------------------------------------------------------\n",
      "We retrieve this subset of parameters:\n",
      " {'L': 128, 'model': 'conv2', 'layers': [256, 128], 'datapath': './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28//', 'outpath': 'out_example', 'datakind': 'image', 'ttkind': 'image'}\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_from_previous=sim.params.outpath+'/'+sim.params.saveModelName\n",
    "params_from_previous, classes_from_previous = hd.ReadArgsTxt(sim.params.outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize a new simulation, but load everything from the files that were generated by the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(L=128, aug=False, bs=32, class_select=None, datakind='mixed', datapath='./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28//', dropout=None, earlyStopping=100, initial_epoch=0, layers=[256, 128], load=None, lr=5e-05, model='mlp', model_feat='mlp', model_image='mlp', opt='sgd', outpath='./out//', plot=False, saveModelName='keras_model.h5', testSplit=0.2, totEpochs=5, training_data=True, ttkind='mixed', verbose=False)\n",
      "datapath: ./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28//\n",
      "classes from datapath: ['kellikottia', 'filament', 'ceratium', 'chaoborus', 'fragilaria', 'dirt', 'daphnia', 'cyclops', 'conochilus', 'leptodora', 'uroglena', 'unknown', 'diaphanosoma', 'bosmina', 'fish', 'asterionella', 'paradileptus', 'keratella_quadrata', 'keratella_cochlearis', 'asplanchna', 'rotifers', 'eudiaptomus', 'trichocerca', 'nauplius', 'maybe_cyano', 'dinobryon', 'unknown_plankton']\n",
      "class: kellikottia (176)\n",
      "class: filament (204)\n",
      "class: ceratium (224)\n",
      "class: chaoborus (5)\n",
      "class: fragilaria (213)\n",
      "class: dirt (103)\n",
      "class: daphnia (522)\n",
      "class: cyclops (569)\n",
      "class: conochilus (64)\n",
      "class: leptodora (196)\n",
      "class: uroglena (872)\n",
      "class: unknown (147)\n",
      "class: diaphanosoma (1089)\n",
      "class: bosmina (48)\n",
      "class: fish (159)\n",
      "class: asterionella (171)\n",
      "class: paradileptus (70)\n",
      "class: keratella_quadrata (227)\n",
      "class: keratella_cochlearis (101)\n",
      "class: asplanchna (321)\n",
      "class: rotifers (155)\n",
      "class: eudiaptomus (372)\n",
      "class: trichocerca (243)\n",
      "class: nauplius (903)\n",
      "class: maybe_cyano (164)\n",
      "class: dinobryon (2928)\n",
      "class: unknown_plankton (47)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sim2=t.Ctrain()\n",
    "\n",
    "\n",
    "sim2.UpdateParams(\n",
    "                outpath='out_example2',\n",
    "                L=params_from_previous['L'],\n",
    "                model=params_from_previous['model'],\n",
    "                datapath=params_from_previous['datapath'],\n",
    "                datakind=params_from_previous['datakind'],\n",
    "                ttkind=params_from_previous['ttkind'],\n",
    "                class_select=classes_from_previous\n",
    "                )\n",
    "\n",
    "sim2.CreateOutDir()\n",
    "sim2.LoadData() # Should make a deep copy from sim\n",
    "sim2.CreateTrainTestSets() # Should make a deep copy from sim\n",
    "sim2.LoadModel(model_from_previous)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          asplanchna       0.93      0.94      0.93        68\n",
      "        asterionella       0.97      0.83      0.90        36\n",
      "             bosmina       0.54      0.54      0.54        13\n",
      "            ceratium       0.79      0.94      0.86        33\n",
      "           chaoborus       0.00      0.00      0.00         1\n",
      "          conochilus       0.88      0.88      0.88         8\n",
      "             cyclops       0.94      0.85      0.89       107\n",
      "             daphnia       0.88      0.85      0.86       113\n",
      "        diaphanosoma       0.92      0.98      0.95       221\n",
      "           dinobryon       0.97      1.00      0.98       593\n",
      "                dirt       0.41      0.35      0.38        20\n",
      "         eudiaptomus       0.84      0.82      0.83        93\n",
      "            filament       0.90      0.97      0.94        38\n",
      "                fish       0.53      0.72      0.61        32\n",
      "          fragilaria       0.92      0.95      0.94        38\n",
      "         kellikottia       0.97      0.94      0.96        36\n",
      "keratella_cochlearis       0.38      0.89      0.53         9\n",
      "  keratella_quadrata       0.93      0.93      0.93        45\n",
      "           leptodora       0.79      0.79      0.79        39\n",
      "         maybe_cyano       0.83      0.89      0.86        28\n",
      "            nauplius       0.99      0.96      0.98       192\n",
      "        paradileptus       1.00      0.69      0.81        16\n",
      "            rotifers       0.68      0.56      0.61        27\n",
      "         trichocerca       0.95      0.91      0.93        45\n",
      "             unknown       0.81      0.38      0.52        34\n",
      "    unknown_plankton       0.33      0.25      0.29        12\n",
      "            uroglena       1.00      0.99      1.00       162\n",
      "\n",
      "            accuracy                           0.91      2059\n",
      "           macro avg       0.78      0.77      0.77      2059\n",
      "        weighted avg       0.92      0.91      0.91      2059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# The classification report should coincide with the one at the end of simulation 1\n",
    "sim2.Report()\n",
    "# sim2.Predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Weights\n",
    "We load the best weights from the callback, and make the classification report again. We expect slightly better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          asplanchna       0.89      0.97      0.93        68\n",
      "        asterionella       0.89      0.89      0.89        36\n",
      "             bosmina       0.64      0.54      0.58        13\n",
      "            ceratium       0.86      0.91      0.88        33\n",
      "           chaoborus       0.00      0.00      0.00         1\n",
      "          conochilus       0.88      0.88      0.88         8\n",
      "             cyclops       0.88      0.93      0.90       107\n",
      "             daphnia       0.85      0.88      0.87       113\n",
      "        diaphanosoma       0.95      0.97      0.96       221\n",
      "           dinobryon       0.98      0.99      0.99       593\n",
      "                dirt       0.46      0.30      0.36        20\n",
      "         eudiaptomus       0.90      0.77      0.83        93\n",
      "            filament       0.83      1.00      0.90        38\n",
      "                fish       0.65      0.69      0.67        32\n",
      "          fragilaria       0.95      0.95      0.95        38\n",
      "         kellikottia       0.97      0.94      0.96        36\n",
      "keratella_cochlearis       0.42      0.56      0.48         9\n",
      "  keratella_quadrata       0.91      0.93      0.92        45\n",
      "           leptodora       0.82      0.72      0.77        39\n",
      "         maybe_cyano       0.79      0.93      0.85        28\n",
      "            nauplius       0.99      0.97      0.98       192\n",
      "        paradileptus       0.92      0.75      0.83        16\n",
      "            rotifers       0.63      0.70      0.67        27\n",
      "         trichocerca       0.93      0.93      0.93        45\n",
      "             unknown       0.70      0.41      0.52        34\n",
      "    unknown_plankton       0.38      0.25      0.30        12\n",
      "            uroglena       1.00      0.99      1.00       162\n",
      "\n",
      "            accuracy                           0.92      2059\n",
      "           macro avg       0.78      0.77      0.77      2059\n",
      "        weighted avg       0.92      0.92      0.92      2059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# BISOGNA FARE LOADING DEI BEST WEIGHTS\n",
    "sim.model.load_weights(sim.params.outpath+'/bestweights.hdf5')\n",
    "# !ls out_example/\n",
    "sim.Report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use second model to predict on new, unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdir = 'data/1_zooplankton_0p5x/validation/tommy_validation/images/dinobryon/'\n",
    "im_names=np.array(glob.glob(testdir+'/*.jpeg'),dtype=object)\n",
    "npimages=hd.LoadImageList(im_names, L=sim2.params.L, show=False)\n",
    "\n",
    "probs=sim2.model.predict(npimages)\n",
    "predictions=probs.argmax(axis=1)  # The class that the classifier would bet on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['dirt' 'dinobryon' 'dinobryon' 'dinobryon' 'keratella_cochlearis'\n",
      " 'dinobryon' 'dinobryon' 'dinobryon' 'dinobryon']\n"
     ]
    }
   ],
   "source": [
    "print('Predictions:',sim2.tt.lb.classes_[predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
