{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import train as t\n",
    "from src import helper_models as hm, helper_data as hd, helper_tts as htts\n",
    "from importlib import reload\n",
    "import keras, glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.helper_tts' from '/mnt/volume2Tb/Dropbox/PROJECTS/MACHINE-LEARNING/AQUASCOPE/plankifier/src/helper_tts.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload imports of custom modules, in case I am modifying and reloading them live\n",
    "reload(t)\n",
    "reload(hd)\n",
    "reload(hm)\n",
    "reload(htts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=t.Ctrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init parameters\n",
    "Parameters must always be updated through the `UpdateParams()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetModelParams(kind):\n",
    "    ''' \n",
    "    A quick way to set compatible user parameters of data and model kinds\n",
    "    \n",
    "    Input: kind = either 'image', 'feat' or 'mixed'\n",
    "    Output: model_image, model_feat, datakind, ttkind, aug\n",
    "    '''\n",
    "    \n",
    "    if kind == 'image':\n",
    "        return ('conv2', None, 'image', 'image', True)\n",
    "    \n",
    "    elif kind == 'feat':\n",
    "        return (None, 'mlp', 'feat', 'feat', False)\n",
    "    \n",
    "    elif kind == 'mixed':\n",
    "        return ('conv2', 'mlp', 'mixed', 'mixed', False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_image, model_feat, datakind, ttkind, aug = SetModelParams('image')\n",
    "\n",
    "sim.UpdateParams(\n",
    "    datapaths=['./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28/',\n",
    "               './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.07.06/'],\n",
    "    outpath     = 'out_example', \n",
    "    L           = 128, \n",
    "    aug         = aug, \n",
    "    model_feat  = model_feat,\n",
    "    model_image = model_image,\n",
    "    datakind    = datakind, \n",
    "    ttkind      = ttkind,\n",
    "    class_select= ['chaoborus','bosmina','unknown_plankton'] #None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output directory only after you've set the right `outpath`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.CreateOutDir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28/', './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.07.06/']\n"
     ]
    }
   ],
   "source": [
    "print(sim.params.datapaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapaths: ['./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28/', './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.07.06/']\n",
      "classes from datapaths: ['diatom_chain', 'paradileptus', 'asplanchna', 'unknown_plankton', 'bosmina', 'keratella_quadrata', 'chaoborus', 'leptodora', 'uroglena', 'trichocerca', 'polyarthra', 'unknown', 'rotifers', 'maybe_cyano', 'copepod_skins', 'dirt', 'synchaeta', 'daphnia', 'aphanizomenon', 'eudiaptomus', 'diaphanosoma', 'keratella_cochlearis', 'kellikottia', 'ceratium', 'asterionella', 'daphnia_skins', 'conochilus', 'filament', 'nauplius', 'cyclops', 'fish', 'hydra', 'dinobryon', 'fragilaria']\n",
      "class: chaoborus (10)\n",
      "class: bosmina (80)\n",
      "class: unknown_plankton (71)\n"
     ]
    }
   ],
   "source": [
    "# These arguments are the defaults\n",
    "reload(hd)\n",
    "sim.LoadData(L=sim.params.L, class_select=sim.params.class_select, datakind=sim.params.datakind) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sets (test and train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.UpdateParams(testSplit=0.25)\n",
    "sim.CreateTrainTestSets(ttkind=sim.params.ttkind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Model\n",
    "Custom parameter changes are made by acting directly on the params class through the `UpdateParams()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING: At the current state, we are taking the default weight initialization, whatever it is. This must change in order to have better control.\n",
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.1549 - accuracy: 0.3409 - val_loss: 1.0989 - val_accuracy: 0.3171\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.9903 - accuracy: 0.5521 - val_loss: 1.0874 - val_accuracy: 0.3659\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.9424 - accuracy: 0.4625 - val_loss: 1.0814 - val_accuracy: 0.3659\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.8719 - accuracy: 0.5417 - val_loss: 1.0752 - val_accuracy: 0.3902\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8727 - accuracy: 0.5341 - val_loss: 1.0690 - val_accuracy: 0.4146\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.8192 - accuracy: 0.6250 - val_loss: 1.0628 - val_accuracy: 0.4390\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.8280 - accuracy: 0.5909 - val_loss: 1.0577 - val_accuracy: 0.4878\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8030 - accuracy: 0.5729 - val_loss: 1.0529 - val_accuracy: 0.5854\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.6790 - accuracy: 0.7273 - val_loss: 1.0503 - val_accuracy: 0.5610\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.7388 - accuracy: 0.6250 - val_loss: 1.0474 - val_accuracy: 0.5610\n",
      "Training took 0.12211518287658692 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n"
     ]
    }
   ],
   "source": [
    "sim.UpdateParams(totEpochs=10)\n",
    "sim.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         bosmina       0.67      0.58      0.62        24\n",
      "       chaoborus       0.00      0.00      0.00         2\n",
      "unknown_plankton       0.45      0.60      0.51        15\n",
      "\n",
      "        accuracy                           0.56        41\n",
      "       macro avg       0.37      0.39      0.38        41\n",
      "    weighted avg       0.55      0.56      0.55        41\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sim.Report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract manually the training loss corresponding to the best weights, so that we can make sure that restarting the simulation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training loss: 1.1618678678165784\n",
      "Best    training loss: 0.7388382156689962\n"
     ]
    }
   ],
   "source": [
    "def BestLoss(history):\n",
    "    ''' Returns the training loss of the point where the validation loss was minimal'''\n",
    "    return history['loss'][np.argmin(history['val_loss'])]\n",
    "def InitLoss(history):\n",
    "    ''' Returns the training loss of the point where the validation loss was minimal'''\n",
    "    return history['loss'][0]\n",
    "\n",
    "# initLoss = InitLoss(sim.history.history)\n",
    "# bestLoss = BestLoss(sim.history.history)\n",
    "\n",
    "print('Initial training loss:',InitLoss(sim.history.history))\n",
    "print('Best    training loss:',BestLoss(sim.history.history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start again from scratch\n",
    "If we train again, the simulation does not start again where it ended, but it starts from scratch.\n",
    "Since the default initialization is random, the initial value will be close to that of the previous run, but not the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: At the current state, we are taking the default weight initialization, whatever it is. This must change in order to have better control.\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.0337 - accuracy: 0.4318 - val_loss: 1.0825 - val_accuracy: 0.6341\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.9202 - accuracy: 0.5521 - val_loss: 1.0762 - val_accuracy: 0.6585\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.9314 - accuracy: 0.4886 - val_loss: 1.0728 - val_accuracy: 0.6341\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.8704 - accuracy: 0.5682 - val_loss: 1.0669 - val_accuracy: 0.6829\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8320 - accuracy: 0.6250 - val_loss: 1.0615 - val_accuracy: 0.6829\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.9140 - accuracy: 0.6146 - val_loss: 1.0604 - val_accuracy: 0.6829\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.7792 - accuracy: 0.6364 - val_loss: 1.0561 - val_accuracy: 0.6585\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.8170 - accuracy: 0.5682 - val_loss: 1.0565 - val_accuracy: 0.6341\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.8527 - accuracy: 0.5568 - val_loss: 1.0525 - val_accuracy: 0.6098\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.8353 - accuracy: 0.6146 - val_loss: 1.0506 - val_accuracy: 0.6585\n",
      "Training took 0.060031700134277347 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n"
     ]
    }
   ],
   "source": [
    "sim.Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training loss: 1.0367931940338828\n",
      "Best    training loss: 0.8353064060211182\n"
     ]
    }
   ],
   "source": [
    "print('Initial training loss:',InitLoss(sim.history.history))\n",
    "print('Best    training loss:',BestLoss(sim.history.history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from a previous state\n",
    "We have two ways of not starting from scratch. We can either *(a)* define the full model and load the weight configuration, or *(b)* load the full model. We could also load the full model and then load a different weight configuration *(b+a)*.\n",
    "\n",
    "I also show how to play around with some input parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Define model and load weights from disk\n",
    "We don't update the parameters, because we keep the same ones as in the previous runs, for comparison. The only thing we need to do, before calling `sim.Train()`, is to specify the file with the weight configuration through the `load_weights` parameter.\n",
    "\n",
    "We will load the weights that minimized the test loss in the previous run.\n",
    "You will see now that the initial loss is lower value than that of the two previous runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  out_example/bestweights.hdf5\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.7844 - accuracy: 0.6250 - val_loss: 1.0469 - val_accuracy: 0.6585\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.8042 - accuracy: 0.5909 - val_loss: 1.0446 - val_accuracy: 0.6585\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.8378 - accuracy: 0.5568 - val_loss: 1.0442 - val_accuracy: 0.6585\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.7187 - accuracy: 0.6875 - val_loss: 1.0405 - val_accuracy: 0.6585\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.7047 - accuracy: 0.7273 - val_loss: 1.0392 - val_accuracy: 0.6585\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.7306 - accuracy: 0.6875 - val_loss: 1.0368 - val_accuracy: 0.6585\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.7643 - accuracy: 0.6136 - val_loss: 1.0348 - val_accuracy: 0.6829\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.7584 - accuracy: 0.5682 - val_loss: 1.0333 - val_accuracy: 0.6098\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.6058 - accuracy: 0.7727 - val_loss: 1.0304 - val_accuracy: 0.6341\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.8443 - accuracy: 0.5682 - val_loss: 1.0306 - val_accuracy: 0.6585\n",
      "Training took 0.062356595198313394 minutes\n",
      "Saving the last model. These are not the best weights, they are the last ones. For the best weights use the callback output (bestweights.hdf5)]\n"
     ]
    }
   ],
   "source": [
    "# Load the weights\n",
    "sim.params.load_weights=sim.params.outpath+'/bestweights.hdf5'\n",
    "sim.Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training loss: 0.790392355485396\n",
      "Best    training loss: 0.6095836162567139\n"
     ]
    }
   ],
   "source": [
    "print('Initial training loss:', InitLoss(sim.history.history))\n",
    "print('Best    training loss:', BestLoss(sim.history.history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Loading full model from disk (CHECKPOINTING)\n",
    "This is essentially what we do when checkpointing. At the end of each run, the entire model is saved (the default name is `'keras_model.h5'`). If we want to restart from there, we just need to load that model.\n",
    "\n",
    "Since in this case we are checkpointing, we also show how to handle the simulation times.\n",
    "Since when checkpointing one usually is starting a simulation from scratch, we will **define a new Ctrain class that loads all the parameters**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model, classes and parameters from the end of the previous run\n",
    "model_from_previous  = sim.params.outpath+'/'+sim.params.saveModelName\n",
    "params_from_previous = np.load(sim.params.outpath+'/params.npy', allow_pickle=True).item()\n",
    "classes_from_previous = np.load(sim.params.outpath+'/classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapaths: ['./data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.04.28/', './data/1_zooplankton_0p5x/training/zooplankton_trainingset_2020.07.06/']\n",
      "classes from datapaths: ['diatom_chain', 'paradileptus', 'asplanchna', 'unknown_plankton', 'bosmina', 'keratella_quadrata', 'chaoborus', 'leptodora', 'uroglena', 'trichocerca', 'polyarthra', 'unknown', 'rotifers', 'maybe_cyano', 'copepod_skins', 'dirt', 'synchaeta', 'daphnia', 'aphanizomenon', 'eudiaptomus', 'diaphanosoma', 'keratella_cochlearis', 'kellikottia', 'ceratium', 'asterionella', 'daphnia_skins', 'conochilus', 'filament', 'nauplius', 'cyclops', 'fish', 'hydra', 'dinobryon', 'fragilaria']\n",
      "class: chaoborus (10)\n",
      "class: bosmina (80)\n",
      "class: unknown_plankton (71)\n"
     ]
    }
   ],
   "source": [
    "# Create a new class, just as if we were starting a new simulation that loaded a previous checkpoint\n",
    "sim2=t.Ctrain()\n",
    "sim2.params = params_from_previous\n",
    "sim2.CreateOutDir()\n",
    "sim2.LoadData(L=sim.params.L, class_select=sim.params.class_select, datakind=sim.params.datakind) # Should make a deep copy from sim\n",
    "sim2.CreateTrainTestSets(ttkind=sim.params.ttkind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model without training it, and make a classification report**. You can see that the model is loaded correctly, since it gives better than random predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         bosmina       0.69      0.83      0.75        24\n",
      "       chaoborus       0.00      0.00      0.00         2\n",
      "unknown_plankton       0.50      0.40      0.44        15\n",
      "\n",
      "        accuracy                           0.63        41\n",
      "       macro avg       0.40      0.41      0.40        41\n",
      "    weighted avg       0.59      0.63      0.60        41\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sim2.LoadModel(modelfile = model_from_previous, bestweights=sim.params.outpath+'/bestweights.hdf5')\n",
    "sim2.Report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prolongate the run for some more steps.\n",
    "Since we are prolongating a run, we also want to make sure that the timesteps are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial epoch to the end of the previous run, and extend the total number of epochs (otherwise it won't run)\n",
    "n_epochs_new = 20\n",
    "\n",
    "sim2.params.initial_epoch=sim.history.epoch[-1]+1 if len(sim.history.epoch)>0 else 0\n",
    "sim2.params.totEpochs=sim2.params.initial_epoch + n_epochs_new\n",
    "\n",
    "# We do not want the Train() method to load weights from somewhere, \n",
    "# so we make sure that load_weights is set to None\n",
    "# If we wanted to load the weights from somewhere, \n",
    "# it would be enough to give it the right file name (usually, 'bestweights.hdf5')\n",
    "sim2.UpdateParams(load_weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs before running: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Loading weights from  None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7049ca818748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs before running:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs after running:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/volume2Tb/Dropbox/PROJECTS/MACHINE-LEARNING/AQUASCOPE/plankifier/train.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m    306\u001b[0m                         \u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/volume2Tb/Dropbox/PROJECTS/MACHINE-LEARNING/AQUASCOPE/plankifier/src/helper_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainX, trainY, testX, testY, params, verbose, numclasses)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetArchitecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Defines self.model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitModelWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# If we are not interested in training, we are only loading the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/volume2Tb/Dropbox/PROJECTS/MACHINE-LEARNING/AQUASCOPE/plankifier/src/helper_models.py\u001b[0m in \u001b[0;36mInitModelWeights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading weights from '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'load_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'load_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ASCII'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrack_order\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/h5py/_hl/compat.py\u001b[0m in \u001b[0;36mfilename_encode\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mfilenames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"win32\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "print('Epochs before running:', sim.history.epoch)\n",
    "sim2.Train()\n",
    "print('Epochs after running:', sim2.history.epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use second model to predict on new, unseen data\n",
    "Choose a class from the ones the classifier can recognize, and see whether the model is able to recognize it when taking unseen images in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We only do this for 'image' models, because the format of the validation directory is wrong and I don't want to cope with that now\n",
    "if ttkind == 'image':\n",
    "    target = sim2.params.class_select[1]\n",
    "    print('target:',target)\n",
    "\n",
    "    testdir = 'data/1_zooplankton_0p5x/validation/tommy_validation/images/'+target\n",
    "    im_names=np.array(glob.glob(testdir+'/*.jpeg'),dtype=object)\n",
    "    npimages=hd.LoadImageList(im_names, L=sim2.params.L, show=False)\n",
    "\n",
    "    probs=sim2.model.predict(npimages)\n",
    "    predictions=probs.argmax(axis=1)  # The class that the classifier would bet on\n",
    "\n",
    "    print('Predictions:',sim2.tt.lb.classes_[predictions])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
